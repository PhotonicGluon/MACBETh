{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b28ee-5261-4dd4-87b9-010886ce0861",
   "metadata": {},
   "source": [
    "# Data Encoder\n",
    "Uses an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bb738e-6c2c-4e35-8eba-5782d2076c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:18:03.458944: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 09:18:04.015804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:18:04.892523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:04.919949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:04.919996: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"GPU is {'not ' if len(tf.config.list_physical_devices('GPU')) == 0 else ''}available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443139d0-df04-4673-afc3-a449c1526a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474614-0625-4708-941d-356be8639d67",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984d982-34ea-4b1c-b270-578980eabe18",
   "metadata": {},
   "source": [
    "The data should already be present as `dataset.csv` and `top_unigrams.txt` in the `data` folder.\n",
    "\n",
    "If they are not present, do the following.\n",
    "1. Ensure that the VirusTotal reports are present in `data/json` with the format `[LABEL]_[HASH].json`.\n",
    "3. Run `prepare_data.py`. This will generate the two files needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a156-3f24-489c-8f21-8227f806efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaf420-a415-4071-85f4-ea273992fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAUTO</td>\n",
       "      <td>c35885d8463d1fe937cf5afb628e5f37ac2c33004b90da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AENJARIS</td>\n",
       "      <td>6eba466355df18050554910e3aece28ac7118d6f9683a2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AENJARIS</td>\n",
       "      <td>a463230d154886983071433608b97630644aeb46fd2a6e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGENTB</td>\n",
       "      <td>0022508fd02bb23c3a2c4f5de0906df506a2fcabc3e841...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGENTB</td>\n",
       "      <td>08174ddc79fd17dee63232b6aa50c79b96d512546aead8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>04d6ff264286ef70cdc08e69cebc09a6cfd2752e5ba3a1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>a368fa01248ecb84c56c87fe65edde7f7d3730e1a37e87...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>dfce96433887553201a295b1475373a82ac6a730f18d88...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>ZEGOST</td>\n",
       "      <td>1367ecca54ac27ce18179d6bfcc0ff93bb7cfb2882dc60...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>ZONIDEL</td>\n",
       "      <td>9e76dfc23658b0add86da8b7bc9b078a3c89bd88dc5782...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               hash  dim-0000  \\\n",
       "0       AAUTO  c35885d8463d1fe937cf5afb628e5f37ac2c33004b90da...         0   \n",
       "1    AENJARIS  6eba466355df18050554910e3aece28ac7118d6f9683a2...         0   \n",
       "2    AENJARIS  a463230d154886983071433608b97630644aeb46fd2a6e...         0   \n",
       "3      AGENTB  0022508fd02bb23c3a2c4f5de0906df506a2fcabc3e841...         0   \n",
       "4      AGENTB  08174ddc79fd17dee63232b6aa50c79b96d512546aead8...         0   \n",
       "..        ...                                                ...       ...   \n",
       "980  ZAPCHAST  04d6ff264286ef70cdc08e69cebc09a6cfd2752e5ba3a1...         0   \n",
       "981  ZAPCHAST  a368fa01248ecb84c56c87fe65edde7f7d3730e1a37e87...         0   \n",
       "982  ZAPCHAST  dfce96433887553201a295b1475373a82ac6a730f18d88...         0   \n",
       "983    ZEGOST  1367ecca54ac27ce18179d6bfcc0ff93bb7cfb2882dc60...         0   \n",
       "984   ZONIDEL  9e76dfc23658b0add86da8b7bc9b078a3c89bd88dc5782...         0   \n",
       "\n",
       "     dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  dim-0007  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "980         0         0         0         0         0         0         0   \n",
       "981         0         0         0         0         0         0         0   \n",
       "982         0         0         0         0         0         0         0   \n",
       "983         0         0         0         0         0         0         0   \n",
       "984         0         0         0         0         0         0         0   \n",
       "\n",
       "     ...  dim-9990  dim-9991  dim-9992  dim-9993  dim-9994  dim-9995  \\\n",
       "0    ...         0         0         0         0         0         0   \n",
       "1    ...         0         0         0         0         0         0   \n",
       "2    ...         0         0         0         0         0         0   \n",
       "3    ...         0         0         0         0         0         0   \n",
       "4    ...         0         0         0         0         0         0   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "980  ...         0         0         0         0         0         0   \n",
       "981  ...         0         0         0         0         0         0   \n",
       "982  ...         0         0         0         0         0         0   \n",
       "983  ...         0         0         0         0         0         0   \n",
       "984  ...         0         0         0         0         0         0   \n",
       "\n",
       "     dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0           0         0         0         0  \n",
       "1           0         0         0         0  \n",
       "2           0         0         0         0  \n",
       "3           0         0         0         0  \n",
       "4           0         0         0         0  \n",
       "..        ...       ...       ...       ...  \n",
       "980         0         0         1         0  \n",
       "981         0         0         0         0  \n",
       "982         0         0         1         0  \n",
       "983         0         0         0         0  \n",
       "984         0         0         0         0  \n",
       "\n",
       "[985 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../data/dataset.csv\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58733-8a7d-492a-9177-3452980c5e16",
   "metadata": {},
   "source": [
    "For the training of the model, we don't need the label or the file hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4d0dbe-2bbf-4067-9376-b7dcf0ca0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>dim-0008</th>\n",
       "      <th>dim-0009</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "980         0         0         0         0         0         0         0   \n",
       "981         0         0         0         0         0         0         0   \n",
       "982         0         0         0         0         0         0         0   \n",
       "983         0         0         0         0         0         0         0   \n",
       "984         0         0         0         0         0         0         0   \n",
       "\n",
       "     dim-0007  dim-0008  dim-0009  ...  dim-9990  dim-9991  dim-9992  \\\n",
       "0           0         0         0  ...         0         0         0   \n",
       "1           0         0         0  ...         0         0         0   \n",
       "2           0         0         0  ...         0         0         0   \n",
       "3           0         0         0  ...         0         0         0   \n",
       "4           0         0         0  ...         0         0         0   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "980         0         0         0  ...         0         0         0   \n",
       "981         0         0         0  ...         0         0         0   \n",
       "982         0         0         0  ...         0         0         0   \n",
       "983         0         0         0  ...         0         0         0   \n",
       "984         0         0         0  ...         0         0         0   \n",
       "\n",
       "     dim-9993  dim-9994  dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0           0         0         0         0         0         0         0  \n",
       "1           0         0         0         0         0         0         0  \n",
       "2           0         0         0         0         0         0         0  \n",
       "3           0         0         0         0         0         0         0  \n",
       "4           0         0         0         0         0         0         0  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "980         0         0         0         0         0         1         0  \n",
       "981         0         0         0         0         0         0         0  \n",
       "982         0         0         0         0         0         1         0  \n",
       "983         0         0         0         0         0         0         0  \n",
       "984         0         0         0         0         0         0         0  \n",
       "\n",
       "[985 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=[\"label\", \"hash\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22399-a9af-45ec-a9b8-39db808eee27",
   "metadata": {},
   "source": [
    "80% of the dataframe will be saved for training, while 20% will be left for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057042e3-70e8-4e06-92d9-cc88f0b5cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3997e3ce-a8aa-40d2-aa00-e32ad3322da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5086b-0ac5-4e0f-b09f-470be173f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eea96-ff4f-4e5d-b5e2-ea82514726bb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215eea-b2ba-4577-984f-2e7e615f854c",
   "metadata": {},
   "source": [
    "We will use an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f209d9f2-8b37-4989-a939-2a28994be8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc4e4-676f-4d5a-bb9b-6a96fba0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_SIZES = [2048, 512, 128, 32]  # The last layer is the center layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf29e26-b748-4fff-af16-8da3c9c459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EPOCH = 0\n",
    "\n",
    "def create_encoder():\n",
    "    model = Sequential(name=\"Encoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[:-1]:\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # Add an activity regularizer to make the middle layer sparse\n",
    "    model.add(layers.Dense(LAYER_SIZES[-1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_decoder():\n",
    "    model = Sequential(name=\"Decoder\")\n",
    "    model.add(keras.Input((LAYER_SIZES[-1],), name=\"decoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[-2::-1]:  # Starting from second last\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(layers.Dense(df.shape[1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_autoencoder(encoder, decoder):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "    model.add(encoder)\n",
    "    model.add(decoder)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a00874-3639-4045-9095-3f73f2e3ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 09:18:06.099695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.099796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.099830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.884910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.884980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.884989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 09:18:06.885026: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 09:18:06.885049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2715 MB memory:  -> device: 0, name: Quadro P1000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "autoencoder = create_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977b48f3-00f2-4281-a3b8-01fbafa39bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,610,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │    \u001b[38;5;34m21,600,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m21,610,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m20,490,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0668d-ef61-44b4-ac88-918bcc3cc14c",
   "metadata": {},
   "source": [
    "Define callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbefdc11-7c6d-440b-adea-5211bae96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"../models/encoder/checkpoints/{epoch:04d}.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05e3cd-5fea-4b37-a1d0-53fa652ca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0d09c-1298-458f-95b7-afa4edf63248",
   "metadata": {},
   "source": [
    "Define some utility functions that help identify the best model trained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d09a1e-d8be-4cec-8568-847b185da274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_model(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    dir_contents = os.listdir(checkpoint_dir)\n",
    "    if len(dir_contents) == 0:\n",
    "        return None\n",
    "    latest_model_path = sorted(dir_contents)[-1]\n",
    "    return latest_model_path\n",
    "\n",
    "\n",
    "def load_latest_model(checkpoint_dir):\n",
    "    latest_model_path = find_latest_model(checkpoint_dir)\n",
    "    if latest_model_path is None:\n",
    "        print(\"No checkpoints found, not loading anything\")\n",
    "        return None\n",
    "    print(f\"Loading '{latest_model_path}'\")\n",
    "    model = keras.models.load_model(os.path.join(checkpoint_dir, latest_model_path))\n",
    "    print(\"Done\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbf576-4890-433a-ab34-723878084111",
   "metadata": {},
   "source": [
    "Load latest checkpoint if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6c2489-b5df-46b6-922b-85b34d67ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_EPOCH = 17\n",
    "# autoencoder = load_latest_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eeb3c-f2c7-41a6-9472-1f876d13c927",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3223132-2248-4545-acc2-d41fbd131c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714353488.826632  636102 service.cc:145] XLA service 0x7fc2cc008250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714353488.826729  636102 service.cc:153]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\n",
      "2024-04-29 09:18:08.858375: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 09:18:09.671575: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0195 - mae: 0.0252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714353492.427882  636102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0182 - mae: 0.0267\n",
      "Epoch 1: val_loss improved from inf to 0.01500, saving model to ../models/encoder/checkpoints/0001.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 293ms/step - loss: 0.0181 - mae: 0.0266 - val_loss: 0.0150 - val_mae: 0.0223\n",
      "Epoch 2/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0144 - mae: 0.0212\n",
      "Epoch 2: val_loss improved from 0.01500 to 0.01348, saving model to ../models/encoder/checkpoints/0002.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0143 - mae: 0.0211 - val_loss: 0.0135 - val_mae: 0.0198\n",
      "Epoch 3/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0128 - mae: 0.0190\n",
      "Epoch 3: val_loss improved from 0.01348 to 0.01185, saving model to ../models/encoder/checkpoints/0003.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0128 - mae: 0.0190 - val_loss: 0.0118 - val_mae: 0.0180\n",
      "Epoch 4/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0120 - mae: 0.0178\n",
      "Epoch 4: val_loss improved from 0.01185 to 0.01100, saving model to ../models/encoder/checkpoints/0004.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0119 - mae: 0.0177 - val_loss: 0.0110 - val_mae: 0.0160\n",
      "Epoch 5/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0105 - mae: 0.0155\n",
      "Epoch 5: val_loss improved from 0.01100 to 0.01034, saving model to ../models/encoder/checkpoints/0005.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0105 - mae: 0.0155 - val_loss: 0.0103 - val_mae: 0.0149\n",
      "Epoch 6/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0095 - mae: 0.0139\n",
      "Epoch 6: val_loss improved from 0.01034 to 0.00989, saving model to ../models/encoder/checkpoints/0006.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0095 - mae: 0.0140 - val_loss: 0.0099 - val_mae: 0.0140\n",
      "Epoch 7/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0098 - mae: 0.0140\n",
      "Epoch 7: val_loss improved from 0.00989 to 0.00965, saving model to ../models/encoder/checkpoints/0007.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0098 - mae: 0.0139 - val_loss: 0.0097 - val_mae: 0.0134\n",
      "Epoch 8/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0097 - mae: 0.0136\n",
      "Epoch 8: val_loss improved from 0.00965 to 0.00958, saving model to ../models/encoder/checkpoints/0008.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0096 - mae: 0.0135 - val_loss: 0.0096 - val_mae: 0.0133\n",
      "Epoch 9/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0087 - mae: 0.0124\n",
      "Epoch 9: val_loss improved from 0.00958 to 0.00938, saving model to ../models/encoder/checkpoints/0009.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0088 - mae: 0.0124 - val_loss: 0.0094 - val_mae: 0.0129\n",
      "Epoch 10/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0087 - mae: 0.0122\n",
      "Epoch 10: val_loss did not improve from 0.00938\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0087 - mae: 0.0122 - val_loss: 0.0095 - val_mae: 0.0134\n",
      "Epoch 11/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0087 - mae: 0.0123\n",
      "Epoch 11: val_loss improved from 0.00938 to 0.00917, saving model to ../models/encoder/checkpoints/0011.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0087 - mae: 0.0123 - val_loss: 0.0092 - val_mae: 0.0126\n",
      "Epoch 12/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0082 - mae: 0.0115\n",
      "Epoch 12: val_loss improved from 0.00917 to 0.00911, saving model to ../models/encoder/checkpoints/0012.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0082 - mae: 0.0115 - val_loss: 0.0091 - val_mae: 0.0127\n",
      "Epoch 13/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0083 - mae: 0.0117\n",
      "Epoch 13: val_loss did not improve from 0.00911\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0083 - mae: 0.0117 - val_loss: 0.0092 - val_mae: 0.0129\n",
      "Epoch 14/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0085 - mae: 0.0120\n",
      "Epoch 14: val_loss improved from 0.00911 to 0.00887, saving model to ../models/encoder/checkpoints/0014.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0085 - mae: 0.0120 - val_loss: 0.0089 - val_mae: 0.0124\n",
      "Epoch 15/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0112\n",
      "Epoch 15: val_loss improved from 0.00887 to 0.00877, saving model to ../models/encoder/checkpoints/0015.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0080 - mae: 0.0112 - val_loss: 0.0088 - val_mae: 0.0119\n",
      "Epoch 16/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0079 - mae: 0.0111\n",
      "Epoch 16: val_loss did not improve from 0.00877\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0079 - mae: 0.0110 - val_loss: 0.0088 - val_mae: 0.0121\n",
      "Epoch 17/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0081 - mae: 0.0113\n",
      "Epoch 17: val_loss did not improve from 0.00877\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0081 - mae: 0.0113 - val_loss: 0.0093 - val_mae: 0.0127\n",
      "Epoch 18/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0081 - mae: 0.0114\n",
      "Epoch 18: val_loss did not improve from 0.00877\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0081 - mae: 0.0113 - val_loss: 0.0088 - val_mae: 0.0122\n",
      "Epoch 19/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - mae: 0.0107\n",
      "Epoch 19: val_loss did not improve from 0.00877\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0076 - mae: 0.0107 - val_loss: 0.0088 - val_mae: 0.0122\n",
      "Epoch 20/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0104\n",
      "Epoch 20: val_loss improved from 0.00877 to 0.00864, saving model to ../models/encoder/checkpoints/0020.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0074 - mae: 0.0104 - val_loss: 0.0086 - val_mae: 0.0118\n",
      "Epoch 21/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0079 - mae: 0.0109\n",
      "Epoch 21: val_loss did not improve from 0.00864\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0079 - mae: 0.0109 - val_loss: 0.0087 - val_mae: 0.0120\n",
      "Epoch 22/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - mae: 0.0105\n",
      "Epoch 22: val_loss improved from 0.00864 to 0.00847, saving model to ../models/encoder/checkpoints/0022.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0075 - mae: 0.0104 - val_loss: 0.0085 - val_mae: 0.0114\n",
      "Epoch 23/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0100\n",
      "Epoch 23: val_loss improved from 0.00847 to 0.00832, saving model to ../models/encoder/checkpoints/0023.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0073 - mae: 0.0100 - val_loss: 0.0083 - val_mae: 0.0112\n",
      "Epoch 24/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0098\n",
      "Epoch 24: val_loss improved from 0.00832 to 0.00823, saving model to ../models/encoder/checkpoints/0024.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0071 - mae: 0.0098 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 25/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0086\n",
      "Epoch 25: val_loss improved from 0.00823 to 0.00819, saving model to ../models/encoder/checkpoints/0025.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0063 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 26/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0069 - mae: 0.0092\n",
      "Epoch 26: val_loss improved from 0.00819 to 0.00815, saving model to ../models/encoder/checkpoints/0026.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0069 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0107\n",
      "Epoch 27/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0087\n",
      "Epoch 27: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0065 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 28/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0067 - mae: 0.0091\n",
      "Epoch 28: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0067 - mae: 0.0091 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 29/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0087\n",
      "Epoch 29: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0087 - val_loss: 0.0083 - val_mae: 0.0111\n",
      "Epoch 30/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0090\n",
      "Epoch 30: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0066 - mae: 0.0090 - val_loss: 0.0085 - val_mae: 0.0113\n",
      "Epoch 31/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0089\n",
      "Epoch 31: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0065 - mae: 0.0089 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 32/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0067 - mae: 0.0093\n",
      "Epoch 32: val_loss did not improve from 0.00815\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 33/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0091\n",
      "Epoch 33: val_loss improved from 0.00815 to 0.00807, saving model to ../models/encoder/checkpoints/0033.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0066 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0107\n",
      "Epoch 34/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0087\n",
      "Epoch 34: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0063 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 35/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0086\n",
      "Epoch 35: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0109\n",
      "Epoch 36/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0086\n",
      "Epoch 36: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0063 - mae: 0.0086 - val_loss: 0.0084 - val_mae: 0.0113\n",
      "Epoch 37/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mae: 0.0092\n",
      "Epoch 37: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0066 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 38/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mae: 0.0085\n",
      "Epoch 38: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0062 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0108\n",
      "Epoch 39/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0084\n",
      "Epoch 39: val_loss did not improve from 0.00807\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0109\n",
      "Epoch 40/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0083\n",
      "Epoch 40: val_loss improved from 0.00807 to 0.00796, saving model to ../models/encoder/checkpoints/0040.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0061 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0104\n",
      "Epoch 41/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - mae: 0.0076\n",
      "Epoch 41: val_loss improved from 0.00796 to 0.00789, saving model to ../models/encoder/checkpoints/0041.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0079 - val_mae: 0.0105\n",
      "Epoch 42/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0078\n",
      "Epoch 42: val_loss did not improve from 0.00789\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0058 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 43/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0077\n",
      "Epoch 43: val_loss improved from 0.00789 to 0.00787, saving model to ../models/encoder/checkpoints/0043.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0059 - mae: 0.0077 - val_loss: 0.0079 - val_mae: 0.0104\n",
      "Epoch 44/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - mae: 0.0070\n",
      "Epoch 44: val_loss improved from 0.00787 to 0.00781, saving model to ../models/encoder/checkpoints/0044.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0054 - mae: 0.0070 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 45/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0067\n",
      "Epoch 45: val_loss improved from 0.00781 to 0.00777, saving model to ../models/encoder/checkpoints/0045.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0052 - mae: 0.0068 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 46/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0072\n",
      "Epoch 46: val_loss improved from 0.00777 to 0.00774, saving model to ../models/encoder/checkpoints/0046.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0056 - mae: 0.0071 - val_loss: 0.0077 - val_mae: 0.0101\n",
      "Epoch 47/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mae: 0.0069\n",
      "Epoch 47: val_loss did not improve from 0.00774\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0055 - mae: 0.0069 - val_loss: 0.0077 - val_mae: 0.0100\n",
      "Epoch 48/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0067\n",
      "Epoch 48: val_loss did not improve from 0.00774\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0053 - mae: 0.0067 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 49/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - mae: 0.0068\n",
      "Epoch 49: val_loss did not improve from 0.00774\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0053 - mae: 0.0068 - val_loss: 0.0078 - val_mae: 0.0102\n",
      "Epoch 50/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mae: 0.0069\n",
      "Epoch 50: val_loss improved from 0.00774 to 0.00771, saving model to ../models/encoder/checkpoints/0050.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0055 - mae: 0.0069 - val_loss: 0.0077 - val_mae: 0.0098\n",
      "Epoch 51/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0051 - mae: 0.0065\n",
      "Epoch 51: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0051 - mae: 0.0065 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 52/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mae: 0.0068\n",
      "Epoch 52: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0055 - mae: 0.0068 - val_loss: 0.0077 - val_mae: 0.0100\n",
      "Epoch 53/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - mae: 0.0067\n",
      "Epoch 53: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0053 - mae: 0.0067 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 54/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0054 - mae: 0.0067\n",
      "Epoch 54: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0054 - mae: 0.0067 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 55/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0053 - mae: 0.0066\n",
      "Epoch 55: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0053 - mae: 0.0066 - val_loss: 0.0077 - val_mae: 0.0099\n",
      "Epoch 56/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0050 - mae: 0.0063\n",
      "Epoch 56: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0051 - mae: 0.0063 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 57/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0065\n",
      "Epoch 57: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0077 - val_mae: 0.0099\n",
      "Epoch 58/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0066\n",
      "Epoch 58: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0052 - mae: 0.0066 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 59/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0051 - mae: 0.0064\n",
      "Epoch 59: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0051 - mae: 0.0064 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 60/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0066\n",
      "Epoch 60: val_loss did not improve from 0.00771\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0078 - val_mae: 0.0099\n",
      "Epoch 60: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc395c3e760>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    validation_split=0.2,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624de2c-db5a-4f66-af5f-46a9ecda2cc6",
   "metadata": {},
   "source": [
    "Load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a49b423-df15-49b1-bf24-240085e1cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '0050.keras'\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "autoencoder = load_latest_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac822d-1e53-4f8f-8276-167436b59306",
   "metadata": {},
   "source": [
    "Evaluate the autoencoder on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4781808-0e8e-4ea4-881d-b8885317b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.0073 - mae: 0.0092\n",
      "Testing MSE: 0.00796\n",
      "Testing MAE: 0.01010\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = autoencoder.evaluate(X_test, X_test, verbose=1)\n",
    "print(f\"Testing MSE: {test_mse:5.5f}\")\n",
    "print(f\"Testing MAE: {test_mae:5.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc591-1499-4c3e-9ba1-c987af35dee0",
   "metadata": {},
   "source": [
    "Get only the encoder part to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801a52f6-c52d-4c03-9cde-7821b653487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.get_layer(\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8480f9-8f94-4625-8a5e-4f6a55a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40297ec-1e27-40ac-873e-e9c1725e5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"../models/encoder/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541ccc-227c-41b1-bc39-dfa5dcd3497f",
   "metadata": {},
   "source": [
    "# Transforming Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e958e27-424d-4d0b-b13e-9b4114b6cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_df = encoder.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe6b34d-e744-447b-9628-a6ef8b508b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(transformed_df, columns=[f\"dim-{i:02d}\" for i in range(LAYER_SIZES[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61444a4-2d51-4b52-808f-86733b39447c",
   "metadata": {},
   "source": [
    "Add the labels and hashes back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f31a8a-5060-4541-bddf-afda870e351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.insert(0, \"label\", raw_df[\"label\"])\n",
    "transformed_df.insert(1, \"hash\", raw_df[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea1b33c5-5b44-4f0c-9996-a413474a9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-00</th>\n",
       "      <th>dim-01</th>\n",
       "      <th>dim-02</th>\n",
       "      <th>dim-03</th>\n",
       "      <th>dim-04</th>\n",
       "      <th>dim-05</th>\n",
       "      <th>dim-06</th>\n",
       "      <th>dim-07</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-22</th>\n",
       "      <th>dim-23</th>\n",
       "      <th>dim-24</th>\n",
       "      <th>dim-25</th>\n",
       "      <th>dim-26</th>\n",
       "      <th>dim-27</th>\n",
       "      <th>dim-28</th>\n",
       "      <th>dim-29</th>\n",
       "      <th>dim-30</th>\n",
       "      <th>dim-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAUTO</td>\n",
       "      <td>c35885d8463d1fe937cf5afb628e5f37ac2c33004b90da...</td>\n",
       "      <td>0.46469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.658468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.977732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.066464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.847954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.958649</td>\n",
       "      <td>5.503294</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>5.570132</td>\n",
       "      <td>6.377898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AENJARIS</td>\n",
       "      <td>6eba466355df18050554910e3aece28ac7118d6f9683a2...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.925267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.161427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.700646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.555328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.576216</td>\n",
       "      <td>0.442560</td>\n",
       "      <td>25.964514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AENJARIS</td>\n",
       "      <td>a463230d154886983071433608b97630644aeb46fd2a6e...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.213775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.369963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.656313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.844568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.629220</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>26.305899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGENTB</td>\n",
       "      <td>0022508fd02bb23c3a2c4f5de0906df506a2fcabc3e841...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.689069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.657124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.291744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.291505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.850214</td>\n",
       "      <td>9.870970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGENTB</td>\n",
       "      <td>08174ddc79fd17dee63232b6aa50c79b96d512546aead8...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.135266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.235934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.588072</td>\n",
       "      <td>7.317095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>04d6ff264286ef70cdc08e69cebc09a6cfd2752e5ba3a1...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.240609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.727724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.688204</td>\n",
       "      <td>16.599146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.045621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>a368fa01248ecb84c56c87fe65edde7f7d3730e1a37e87...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.219143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.790781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.824963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.004188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.681213</td>\n",
       "      <td>5.848680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ZAPCHAST</td>\n",
       "      <td>dfce96433887553201a295b1475373a82ac6a730f18d88...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.820048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.915873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.068173</td>\n",
       "      <td>14.177855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>ZEGOST</td>\n",
       "      <td>1367ecca54ac27ce18179d6bfcc0ff93bb7cfb2882dc60...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.703352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.974449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.804555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.894542</td>\n",
       "      <td>26.230101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>ZONIDEL</td>\n",
       "      <td>9e76dfc23658b0add86da8b7bc9b078a3c89bd88dc5782...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.360672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.763356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.303043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.878826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.204029</td>\n",
       "      <td>3.245556</td>\n",
       "      <td>11.187321</td>\n",
       "      <td>17.774897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               hash   dim-00  \\\n",
       "0       AAUTO  c35885d8463d1fe937cf5afb628e5f37ac2c33004b90da...  0.46469   \n",
       "1    AENJARIS  6eba466355df18050554910e3aece28ac7118d6f9683a2...  0.00000   \n",
       "2    AENJARIS  a463230d154886983071433608b97630644aeb46fd2a6e...  0.00000   \n",
       "3      AGENTB  0022508fd02bb23c3a2c4f5de0906df506a2fcabc3e841...  0.00000   \n",
       "4      AGENTB  08174ddc79fd17dee63232b6aa50c79b96d512546aead8...  0.00000   \n",
       "..        ...                                                ...      ...   \n",
       "980  ZAPCHAST  04d6ff264286ef70cdc08e69cebc09a6cfd2752e5ba3a1...  0.00000   \n",
       "981  ZAPCHAST  a368fa01248ecb84c56c87fe65edde7f7d3730e1a37e87...  0.00000   \n",
       "982  ZAPCHAST  dfce96433887553201a295b1475373a82ac6a730f18d88...  0.00000   \n",
       "983    ZEGOST  1367ecca54ac27ce18179d6bfcc0ff93bb7cfb2882dc60...  0.00000   \n",
       "984   ZONIDEL  9e76dfc23658b0add86da8b7bc9b078a3c89bd88dc5782...  0.00000   \n",
       "\n",
       "     dim-01  dim-02     dim-03  dim-04     dim-05  dim-06     dim-07  ...  \\\n",
       "0       0.0     0.0  11.658468     0.0   2.977732     0.0   7.066464  ...   \n",
       "1       0.0     0.0  12.925267     0.0  18.161427     0.0  10.700646  ...   \n",
       "2       0.0     0.0  13.213775     0.0  18.369963     0.0  10.656313  ...   \n",
       "3       0.0     0.0  14.689069     0.0   6.657124     0.0   0.000000  ...   \n",
       "4       0.0     0.0   0.000000     0.0   1.135266     0.0   0.000000  ...   \n",
       "..      ...     ...        ...     ...        ...     ...        ...  ...   \n",
       "980     0.0     0.0   2.240609     0.0  13.727724     0.0   0.000000  ...   \n",
       "981     0.0     0.0   5.219143     0.0  12.790781     0.0   0.000000  ...   \n",
       "982     0.0     0.0   0.000000     0.0  10.820048     0.0   0.000000  ...   \n",
       "983     0.0     0.0   0.000000     0.0   1.703352     0.0   0.364429  ...   \n",
       "984     0.0     0.0  19.360672     0.0  10.763356     0.0   6.303043  ...   \n",
       "\n",
       "       dim-22     dim-23  dim-24    dim-25  dim-26    dim-27     dim-28  \\\n",
       "0    0.000000  17.847954     0.0  0.000000     0.0  3.958649   5.503294   \n",
       "1    0.000000  25.555328     0.0  0.000000     0.0  0.000000   0.000000   \n",
       "2    0.000000  25.844568     0.0  0.000000     0.0  0.000000   0.000000   \n",
       "3    0.000000  12.291744     0.0  5.291505     0.0  0.000000   0.000000   \n",
       "4    0.000000   7.235934     0.0  0.000000     0.0  0.000000   0.901341   \n",
       "..        ...        ...     ...       ...     ...       ...        ...   \n",
       "980  3.688204  16.599146     0.0  0.000000     0.0  0.000000   0.000000   \n",
       "981  0.000000  10.824963     0.0  2.004188     0.0  0.000000   0.000000   \n",
       "982  0.000000   9.915873     0.0  0.000000     0.0  0.000000   0.000000   \n",
       "983  0.000000  13.974449     0.0  0.000000     0.0  0.000000  12.804555   \n",
       "984  0.000000  16.878826     0.0  0.000000     0.0  0.000000   2.204029   \n",
       "\n",
       "        dim-29     dim-30     dim-31  \n",
       "0     0.061921   5.570132   6.377898  \n",
       "1    10.576216   0.442560  25.964514  \n",
       "2    10.629220   0.955844  26.305899  \n",
       "3     0.000000  21.850214   9.870970  \n",
       "4     0.000000   3.588072   7.317095  \n",
       "..         ...        ...        ...  \n",
       "980   0.000000   0.000000   6.045621  \n",
       "981   0.000000   9.681213   5.848680  \n",
       "982   0.000000   1.068173  14.177855  \n",
       "983   0.000000   2.894542  26.230101  \n",
       "984   3.245556  11.187321  17.774897  \n",
       "\n",
       "[985 rows x 34 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "373a284e-8b46-417e-acf4-430b511ddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../data/encoded-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
