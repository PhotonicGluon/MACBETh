{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b28ee-5261-4dd4-87b9-010886ce0861",
   "metadata": {},
   "source": [
    "# Data Encoder\n",
    "Uses an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bb738e-6c2c-4e35-8eba-5782d2076c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 11:14:59.463675: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 11:15:00.084914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 11:15:00.917456: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:00.954670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:00.954725: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"GPU is {'not ' if len(tf.config.list_physical_devices('GPU')) == 0 else ''}available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443139d0-df04-4673-afc3-a449c1526a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474614-0625-4708-941d-356be8639d67",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984d982-34ea-4b1c-b270-578980eabe18",
   "metadata": {},
   "source": [
    "The data should already be present as `dataset.csv` and `top_unigrams.txt` in the `data` folder.\n",
    "\n",
    "If they are not present, do the following.\n",
    "1. Ensure that the VirusTotal reports are present in `data/json` with the format `[LABEL]_[HASH].json`.\n",
    "3. Run `prepare_data.py`. This will generate the two files needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a156-3f24-489c-8f21-8227f806efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaf420-a415-4071-85f4-ea273992fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECHELON</td>\n",
       "      <td>5b3f895f7fc0f82147f36989f7c007dc73ea30297d2a53...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>6acde9d1d6882f75cdd14eeeb4821711734bd5cbee49c0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIVE</td>\n",
       "      <td>122e397dc3a55143bd276d6ff3bc04a05601fbf390aa52...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BABAR</td>\n",
       "      <td>7433bab5f01f1a93a2e40017bbbb209309a5fc14f12c80...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>STEAM</td>\n",
       "      <td>60f2ab502f2809fa7e33e43905c5b9e77080d4cf5d1f28...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               hash  \\\n",
       "0    INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "1         ECHELON  5b3f895f7fc0f82147f36989f7c007dc73ea30297d2a53...   \n",
       "2         UNKNOWN  6acde9d1d6882f75cdd14eeeb4821711734bd5cbee49c0...   \n",
       "3            HIVE  122e397dc3a55143bd276d6ff3bc04a05601fbf390aa52...   \n",
       "4           BABAR  7433bab5f01f1a93a2e40017bbbb209309a5fc14f12c80...   \n",
       "..            ...                                                ...   \n",
       "995         STEAM  60f2ab502f2809fa7e33e43905c5b9e77080d4cf5d1f28...   \n",
       "996       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "997      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "998       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "999      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "     dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995         0         0         0         0         0         0         0   \n",
       "996         0         0         0         0         0         0         0   \n",
       "997         0         0         0         0         0         0         0   \n",
       "998         0         0         0         0         0         0         0   \n",
       "999         0         0         0         0         0         0         0   \n",
       "\n",
       "     dim-0007  ...  dim-9990  dim-9991  dim-9992  dim-9993  dim-9994  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "..        ...  ...       ...       ...       ...       ...       ...   \n",
       "995         0  ...         0         0         0         0         0   \n",
       "996         0  ...         0         0         0         0         0   \n",
       "997         0  ...         0         0         0         0         0   \n",
       "998         0  ...         0         0         0         0         0   \n",
       "999         0  ...         0         0         0         0         0   \n",
       "\n",
       "     dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0           0         0         0         0         0  \n",
       "1           0         0         0         0         0  \n",
       "2           0         0         0         0         0  \n",
       "3           0         0         0         0         0  \n",
       "4           0         0         0         1         1  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "995         0         0         0         0         0  \n",
       "996         0         0         0         0         0  \n",
       "997         0         0         0         0         0  \n",
       "998         0         0         0         0         0  \n",
       "999         0         0         0         0         0  \n",
       "\n",
       "[1000 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../data/dataset.csv\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58733-8a7d-492a-9177-3452980c5e16",
   "metadata": {},
   "source": [
    "For the training of the model, we don't need the label or the file hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4d0dbe-2bbf-4067-9376-b7dcf0ca0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>dim-0008</th>\n",
       "      <th>dim-0009</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995         0         0         0         0         0         0         0   \n",
       "996         0         0         0         0         0         0         0   \n",
       "997         0         0         0         0         0         0         0   \n",
       "998         0         0         0         0         0         0         0   \n",
       "999         0         0         0         0         0         0         0   \n",
       "\n",
       "     dim-0007  dim-0008  dim-0009  ...  dim-9990  dim-9991  dim-9992  \\\n",
       "0           0         0         0  ...         0         0         0   \n",
       "1           0         0         0  ...         0         0         0   \n",
       "2           0         0         0  ...         0         0         0   \n",
       "3           0         0         0  ...         0         0         0   \n",
       "4           0         0         0  ...         0         0         0   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995         0         0         0  ...         0         0         0   \n",
       "996         0         0         0  ...         0         0         0   \n",
       "997         0         0         0  ...         0         0         0   \n",
       "998         0         0         0  ...         0         0         0   \n",
       "999         0         0         0  ...         0         0         0   \n",
       "\n",
       "     dim-9993  dim-9994  dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0           0         0         0         0         0         0         0  \n",
       "1           0         0         0         0         0         0         0  \n",
       "2           0         0         0         0         0         0         0  \n",
       "3           0         0         0         0         0         0         0  \n",
       "4           0         0         0         0         0         1         1  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995         0         0         0         0         0         0         0  \n",
       "996         0         0         0         0         0         0         0  \n",
       "997         0         0         0         0         0         0         0  \n",
       "998         0         0         0         0         0         0         0  \n",
       "999         0         0         0         0         0         0         0  \n",
       "\n",
       "[1000 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=[\"label\", \"hash\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22399-a9af-45ec-a9b8-39db808eee27",
   "metadata": {},
   "source": [
    "80% of the dataframe will be saved for training, while 20% will be left for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057042e3-70e8-4e06-92d9-cc88f0b5cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3997e3ce-a8aa-40d2-aa00-e32ad3322da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5086b-0ac5-4e0f-b09f-470be173f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eea96-ff4f-4e5d-b5e2-ea82514726bb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215eea-b2ba-4577-984f-2e7e615f854c",
   "metadata": {},
   "source": [
    "We will use an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f209d9f2-8b37-4989-a939-2a28994be8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc4e4-676f-4d5a-bb9b-6a96fba0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_SIZES = [2048, 512, 128, 32]  # The last layer is the center layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf29e26-b748-4fff-af16-8da3c9c459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EPOCH = 0\n",
    "\n",
    "def create_encoder():\n",
    "    model = Sequential(name=\"Encoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[:-1]:\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # Add an activity regularizer to make the middle layer sparse\n",
    "    model.add(layers.Dense(LAYER_SIZES[-1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_decoder():\n",
    "    model = Sequential(name=\"Decoder\")\n",
    "    model.add(keras.Input((LAYER_SIZES[-1],), name=\"decoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[-2::-1]:  # Starting from second last\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(layers.Dense(df.shape[1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_autoencoder(encoder, decoder):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "    model.add(encoder)\n",
    "    model.add(decoder)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a00874-3639-4045-9095-3f73f2e3ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 11:15:02.176604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.176735: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.176769: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.982442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.982519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.982528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 11:15:02.982565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 11:15:02.982590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2715 MB memory:  -> device: 0, name: Quadro P1000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "autoencoder = create_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977b48f3-00f2-4281-a3b8-01fbafa39bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,610,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │    \u001b[38;5;34m21,600,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m21,610,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m20,490,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0668d-ef61-44b4-ac88-918bcc3cc14c",
   "metadata": {},
   "source": [
    "Define callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbefdc11-7c6d-440b-adea-5211bae96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"../models/encoder/checkpoints/{epoch:04d}.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05e3cd-5fea-4b37-a1d0-53fa652ca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0d09c-1298-458f-95b7-afa4edf63248",
   "metadata": {},
   "source": [
    "Define some utility functions that help identify the best model trained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d09a1e-d8be-4cec-8568-847b185da274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_model(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    dir_contents = os.listdir(checkpoint_dir)\n",
    "    if len(dir_contents) == 0:\n",
    "        return None\n",
    "    latest_model_path = sorted(dir_contents)[-1]\n",
    "    return latest_model_path\n",
    "\n",
    "\n",
    "def load_latest_model(checkpoint_dir):\n",
    "    latest_model_path = find_latest_model(checkpoint_dir)\n",
    "    if latest_model_path is None:\n",
    "        print(\"No checkpoints found, not loading anything\")\n",
    "        return None\n",
    "    print(f\"Loading '{latest_model_path}'\")\n",
    "    model = keras.models.load_model(os.path.join(checkpoint_dir, latest_model_path))\n",
    "    print(\"Done\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbf576-4890-433a-ab34-723878084111",
   "metadata": {},
   "source": [
    "Load latest checkpoint if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6c2489-b5df-46b6-922b-85b34d67ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_EPOCH = 17\n",
    "# autoencoder = load_latest_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eeb3c-f2c7-41a6-9472-1f876d13c927",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3223132-2248-4545-acc2-d41fbd131c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714360504.957948  835033 service.cc:145] XLA service 0x7fb0ec013880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714360504.958024  835033 service.cc:153]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\n",
      "2024-04-29 11:15:04.991383: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 11:15:05.828556: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0202 - mae: 0.0275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714360508.595718  835033 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0184 - mae: 0.0273\n",
      "Epoch 1: val_loss improved from inf to 0.01594, saving model to ../models/encoder/checkpoints/0001.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - loss: 0.0183 - mae: 0.0271 - val_loss: 0.0159 - val_mae: 0.0231\n",
      "Epoch 2/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0140 - mae: 0.0205\n",
      "Epoch 2: val_loss improved from 0.01594 to 0.01380, saving model to ../models/encoder/checkpoints/0002.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0140 - mae: 0.0205 - val_loss: 0.0138 - val_mae: 0.0204\n",
      "Epoch 3/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0124 - mae: 0.0188\n",
      "Epoch 3: val_loss improved from 0.01380 to 0.01271, saving model to ../models/encoder/checkpoints/0003.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0123 - mae: 0.0187 - val_loss: 0.0127 - val_mae: 0.0187\n",
      "Epoch 4/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0113 - mae: 0.0168\n",
      "Epoch 4: val_loss improved from 0.01271 to 0.01188, saving model to ../models/encoder/checkpoints/0004.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0113 - mae: 0.0167 - val_loss: 0.0119 - val_mae: 0.0169\n",
      "Epoch 5/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0109 - mae: 0.0157\n",
      "Epoch 5: val_loss improved from 0.01188 to 0.01114, saving model to ../models/encoder/checkpoints/0005.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0108 - mae: 0.0157 - val_loss: 0.0111 - val_mae: 0.0158\n",
      "Epoch 6/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0102 - mae: 0.0147\n",
      "Epoch 6: val_loss improved from 0.01114 to 0.01073, saving model to ../models/encoder/checkpoints/0006.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0102 - mae: 0.0147 - val_loss: 0.0107 - val_mae: 0.0151\n",
      "Epoch 7/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0100 - mae: 0.0143\n",
      "Epoch 7: val_loss improved from 0.01073 to 0.01065, saving model to ../models/encoder/checkpoints/0007.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0100 - mae: 0.0142 - val_loss: 0.0106 - val_mae: 0.0154\n",
      "Epoch 8/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0094 - mae: 0.0135\n",
      "Epoch 8: val_loss improved from 0.01065 to 0.01026, saving model to ../models/encoder/checkpoints/0008.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0094 - mae: 0.0135 - val_loss: 0.0103 - val_mae: 0.0144\n",
      "Epoch 9/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0089 - mae: 0.0126\n",
      "Epoch 9: val_loss improved from 0.01026 to 0.01023, saving model to ../models/encoder/checkpoints/0009.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0090 - mae: 0.0126 - val_loss: 0.0102 - val_mae: 0.0144\n",
      "Epoch 10/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0091 - mae: 0.0129\n",
      "Epoch 10: val_loss improved from 0.01023 to 0.00995, saving model to ../models/encoder/checkpoints/0010.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0091 - mae: 0.0129 - val_loss: 0.0099 - val_mae: 0.0138\n",
      "Epoch 11/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0088 - mae: 0.0125\n",
      "Epoch 11: val_loss did not improve from 0.00995\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0088 - mae: 0.0125 - val_loss: 0.0100 - val_mae: 0.0139\n",
      "Epoch 12/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0085 - mae: 0.0119\n",
      "Epoch 12: val_loss improved from 0.00995 to 0.00987, saving model to ../models/encoder/checkpoints/0012.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0085 - mae: 0.0119 - val_loss: 0.0099 - val_mae: 0.0138\n",
      "Epoch 13/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0114\n",
      "Epoch 13: val_loss did not improve from 0.00987\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0080 - mae: 0.0115 - val_loss: 0.0099 - val_mae: 0.0139\n",
      "Epoch 14/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0088 - mae: 0.0122\n",
      "Epoch 14: val_loss did not improve from 0.00987\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0088 - mae: 0.0122 - val_loss: 0.0099 - val_mae: 0.0138\n",
      "Epoch 15/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0085 - mae: 0.0119\n",
      "Epoch 15: val_loss improved from 0.00987 to 0.00964, saving model to ../models/encoder/checkpoints/0015.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0085 - mae: 0.0119 - val_loss: 0.0096 - val_mae: 0.0134\n",
      "Epoch 16/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0112\n",
      "Epoch 16: val_loss improved from 0.00964 to 0.00924, saving model to ../models/encoder/checkpoints/0016.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0080 - mae: 0.0112 - val_loss: 0.0092 - val_mae: 0.0127\n",
      "Epoch 17/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0100\n",
      "Epoch 17: val_loss did not improve from 0.00924\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0072 - mae: 0.0101 - val_loss: 0.0093 - val_mae: 0.0129\n",
      "Epoch 18/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0102\n",
      "Epoch 18: val_loss improved from 0.00924 to 0.00919, saving model to ../models/encoder/checkpoints/0018.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0074 - mae: 0.0102 - val_loss: 0.0092 - val_mae: 0.0126\n",
      "Epoch 19/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0103\n",
      "Epoch 19: val_loss improved from 0.00919 to 0.00904, saving model to ../models/encoder/checkpoints/0019.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0074 - mae: 0.0103 - val_loss: 0.0090 - val_mae: 0.0123\n",
      "Epoch 20/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0101\n",
      "Epoch 20: val_loss improved from 0.00904 to 0.00893, saving model to ../models/encoder/checkpoints/0020.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0073 - mae: 0.0101 - val_loss: 0.0089 - val_mae: 0.0121\n",
      "Epoch 21/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0072 - mae: 0.0100\n",
      "Epoch 21: val_loss improved from 0.00893 to 0.00891, saving model to ../models/encoder/checkpoints/0021.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0072 - mae: 0.0100 - val_loss: 0.0089 - val_mae: 0.0119\n",
      "Epoch 22/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0097\n",
      "Epoch 22: val_loss improved from 0.00891 to 0.00887, saving model to ../models/encoder/checkpoints/0022.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0071 - mae: 0.0097 - val_loss: 0.0089 - val_mae: 0.0119\n",
      "Epoch 23/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0099\n",
      "Epoch 23: val_loss did not improve from 0.00887\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0071 - mae: 0.0099 - val_loss: 0.0089 - val_mae: 0.0122\n",
      "Epoch 24/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0091\n",
      "Epoch 24: val_loss did not improve from 0.00887\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0092 - val_mae: 0.0126\n",
      "Epoch 25/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - mae: 0.0106\n",
      "Epoch 25: val_loss did not improve from 0.00887\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0075 - mae: 0.0106 - val_loss: 0.0094 - val_mae: 0.0128\n",
      "Epoch 26/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0079 - mae: 0.0109\n",
      "Epoch 26: val_loss did not improve from 0.00887\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0079 - mae: 0.0108 - val_loss: 0.0090 - val_mae: 0.0124\n",
      "Epoch 27/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0100\n",
      "Epoch 27: val_loss improved from 0.00887 to 0.00887, saving model to ../models/encoder/checkpoints/0027.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0072 - mae: 0.0100 - val_loss: 0.0089 - val_mae: 0.0121\n",
      "Epoch 28/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0070 - mae: 0.0097\n",
      "Epoch 28: val_loss did not improve from 0.00887\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0070 - mae: 0.0097 - val_loss: 0.0089 - val_mae: 0.0123\n",
      "Epoch 29/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0067 - mae: 0.0093\n",
      "Epoch 29: val_loss improved from 0.00887 to 0.00867, saving model to ../models/encoder/checkpoints/0029.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0067 - mae: 0.0093 - val_loss: 0.0087 - val_mae: 0.0117\n",
      "Epoch 30/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0087\n",
      "Epoch 30: val_loss improved from 0.00867 to 0.00861, saving model to ../models/encoder/checkpoints/0030.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0063 - mae: 0.0087 - val_loss: 0.0086 - val_mae: 0.0116\n",
      "Epoch 31/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0087\n",
      "Epoch 31: val_loss improved from 0.00861 to 0.00851, saving model to ../models/encoder/checkpoints/0031.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0063 - mae: 0.0087 - val_loss: 0.0085 - val_mae: 0.0113\n",
      "Epoch 32/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0088\n",
      "Epoch 32: val_loss did not improve from 0.00851\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0065 - mae: 0.0088 - val_loss: 0.0085 - val_mae: 0.0113\n",
      "Epoch 33/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mae: 0.0083\n",
      "Epoch 33: val_loss improved from 0.00851 to 0.00850, saving model to ../models/encoder/checkpoints/0033.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0062 - mae: 0.0083 - val_loss: 0.0085 - val_mae: 0.0114\n",
      "Epoch 34/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0080\n",
      "Epoch 34: val_loss improved from 0.00850 to 0.00838, saving model to ../models/encoder/checkpoints/0034.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0059 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0110\n",
      "Epoch 35/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0081\n",
      "Epoch 35: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0110\n",
      "Epoch 36/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0079\n",
      "Epoch 36: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0059 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0111\n",
      "Epoch 37/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0081\n",
      "Epoch 37: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0080 - val_loss: 0.0084 - val_mae: 0.0110\n",
      "Epoch 38/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0081\n",
      "Epoch 38: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0110\n",
      "Epoch 39/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0058 - mae: 0.0077\n",
      "Epoch 39: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0058 - mae: 0.0077 - val_loss: 0.0084 - val_mae: 0.0109\n",
      "Epoch 40/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0059 - mae: 0.0078\n",
      "Epoch 40: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0059 - mae: 0.0078 - val_loss: 0.0087 - val_mae: 0.0116\n",
      "Epoch 41/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0086\n",
      "Epoch 41: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0110\n",
      "Epoch 42/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0076\n",
      "Epoch 42: val_loss improved from 0.00838 to 0.00838, saving model to ../models/encoder/checkpoints/0042.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0084 - val_mae: 0.0108\n",
      "Epoch 43/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0081\n",
      "Epoch 43: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0060 - mae: 0.0081 - val_loss: 0.0088 - val_mae: 0.0116\n",
      "Epoch 44/200\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0077\n",
      "Epoch 44: val_loss did not improve from 0.00838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0058 - mae: 0.0078 - val_loss: 0.0085 - val_mae: 0.0112\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb1c0329c40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    validation_split=0.2,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624de2c-db5a-4f66-af5f-46a9ecda2cc6",
   "metadata": {},
   "source": [
    "Load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a49b423-df15-49b1-bf24-240085e1cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '0042.keras'\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "autoencoder = load_latest_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac822d-1e53-4f8f-8276-167436b59306",
   "metadata": {},
   "source": [
    "Evaluate the autoencoder on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4781808-0e8e-4ea4-881d-b8885317b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 0.0074 - mae: 0.0098\n",
      "Testing MSE: 0.00760\n",
      "Testing MAE: 0.01000\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = autoencoder.evaluate(X_test, X_test, verbose=1)\n",
    "print(f\"Testing MSE: {test_mse:5.5f}\")\n",
    "print(f\"Testing MAE: {test_mae:5.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc591-1499-4c3e-9ba1-c987af35dee0",
   "metadata": {},
   "source": [
    "Get only the encoder part to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801a52f6-c52d-4c03-9cde-7821b653487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.get_layer(\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8480f9-8f94-4625-8a5e-4f6a55a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40297ec-1e27-40ac-873e-e9c1725e5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"../models/encoder/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541ccc-227c-41b1-bc39-dfa5dcd3497f",
   "metadata": {},
   "source": [
    "# Transforming Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e958e27-424d-4d0b-b13e-9b4114b6cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_df = encoder.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe6b34d-e744-447b-9628-a6ef8b508b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(transformed_df, columns=[f\"dim-{i:02d}\" for i in range(LAYER_SIZES[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61444a4-2d51-4b52-808f-86733b39447c",
   "metadata": {},
   "source": [
    "Add the labels and hashes back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f31a8a-5060-4541-bddf-afda870e351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.insert(0, \"label\", raw_df[\"label\"])\n",
    "transformed_df.insert(1, \"hash\", raw_df[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea1b33c5-5b44-4f0c-9996-a413474a9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-00</th>\n",
       "      <th>dim-01</th>\n",
       "      <th>dim-02</th>\n",
       "      <th>dim-03</th>\n",
       "      <th>dim-04</th>\n",
       "      <th>dim-05</th>\n",
       "      <th>dim-06</th>\n",
       "      <th>dim-07</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-22</th>\n",
       "      <th>dim-23</th>\n",
       "      <th>dim-24</th>\n",
       "      <th>dim-25</th>\n",
       "      <th>dim-26</th>\n",
       "      <th>dim-27</th>\n",
       "      <th>dim-28</th>\n",
       "      <th>dim-29</th>\n",
       "      <th>dim-30</th>\n",
       "      <th>dim-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>4.856040</td>\n",
       "      <td>9.959021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.447541</td>\n",
       "      <td>15.384576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.584654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.597068</td>\n",
       "      <td>18.320045</td>\n",
       "      <td>14.764016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.787311</td>\n",
       "      <td>14.470059</td>\n",
       "      <td>6.384356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECHELON</td>\n",
       "      <td>5b3f895f7fc0f82147f36989f7c007dc73ea30297d2a53...</td>\n",
       "      <td>1.294422</td>\n",
       "      <td>1.419385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.093320</td>\n",
       "      <td>0.228263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.231664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.180888</td>\n",
       "      <td>12.521391</td>\n",
       "      <td>3.648764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.218205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>6acde9d1d6882f75cdd14eeeb4821711734bd5cbee49c0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.652483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.523965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263224</td>\n",
       "      <td>1.655028</td>\n",
       "      <td>5.390357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.058898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIVE</td>\n",
       "      <td>122e397dc3a55143bd276d6ff3bc04a05601fbf390aa52...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.312020</td>\n",
       "      <td>5.555528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.241326</td>\n",
       "      <td>1.654186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.521163</td>\n",
       "      <td>3.160460</td>\n",
       "      <td>1.162947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BABAR</td>\n",
       "      <td>7433bab5f01f1a93a2e40017bbbb209309a5fc14f12c80...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.491501</td>\n",
       "      <td>0.805943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.028772</td>\n",
       "      <td>8.230105</td>\n",
       "      <td>5.101253</td>\n",
       "      <td>8.374162</td>\n",
       "      <td>21.305746</td>\n",
       "      <td>15.721295</td>\n",
       "      <td>19.534620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>STEAM</td>\n",
       "      <td>60f2ab502f2809fa7e33e43905c5b9e77080d4cf5d1f28...</td>\n",
       "      <td>1.527257</td>\n",
       "      <td>2.814117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.827382</td>\n",
       "      <td>1.454555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.268779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>8.933444</td>\n",
       "      <td>15.012127</td>\n",
       "      <td>2.206023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.774734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.795664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.074182</td>\n",
       "      <td>0.344437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.211108</td>\n",
       "      <td>0.350439</td>\n",
       "      <td>4.660242</td>\n",
       "      <td>11.047058</td>\n",
       "      <td>10.957180</td>\n",
       "      <td>3.310024</td>\n",
       "      <td>4.528979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.311330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.001150</td>\n",
       "      <td>0.945593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.007902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.340590</td>\n",
       "      <td>9.846880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.200933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.297989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.956394</td>\n",
       "      <td>4.991206</td>\n",
       "      <td>0.331093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.002688</td>\n",
       "      <td>2.819596</td>\n",
       "      <td>3.323392</td>\n",
       "      <td>4.793574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.116982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.125957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.377460</td>\n",
       "      <td>2.357505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               hash  \\\n",
       "0    INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "1         ECHELON  5b3f895f7fc0f82147f36989f7c007dc73ea30297d2a53...   \n",
       "2         UNKNOWN  6acde9d1d6882f75cdd14eeeb4821711734bd5cbee49c0...   \n",
       "3            HIVE  122e397dc3a55143bd276d6ff3bc04a05601fbf390aa52...   \n",
       "4           BABAR  7433bab5f01f1a93a2e40017bbbb209309a5fc14f12c80...   \n",
       "..            ...                                                ...   \n",
       "995         STEAM  60f2ab502f2809fa7e33e43905c5b9e77080d4cf5d1f28...   \n",
       "996       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "997      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "998       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "999      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "       dim-00     dim-01    dim-02     dim-03     dim-04    dim-05     dim-06  \\\n",
       "0    4.856040   9.959021  0.000000   5.447541  15.384576  0.000000   4.584654   \n",
       "1    1.294422   1.419385  0.000000  12.093320   0.228263  0.000000   4.231664   \n",
       "2    0.000000   0.160647  0.000000   4.652483   0.000000  0.000000   0.000000   \n",
       "3    0.000000   0.000000  2.312020   5.555528   0.000000  0.000000   3.241326   \n",
       "4    0.000000   0.000000  0.000000   0.000000   0.000000  0.000000  18.491501   \n",
       "..        ...        ...       ...        ...        ...       ...        ...   \n",
       "995  1.527257   2.814117  0.000000  14.827382   1.454555  0.000000   3.268779   \n",
       "996  0.000000   0.000000  0.000000   4.795664   0.000000  0.000000  10.074182   \n",
       "997  0.000000  11.311330  0.000000  18.001150   0.945593  0.000000   6.007902   \n",
       "998  0.000000   0.000000  0.000000   4.297989   0.000000  0.000000   0.000000   \n",
       "999  0.000000   0.000000  2.002688   2.819596   3.323392  4.793574   0.000000   \n",
       "\n",
       "       dim-07  ...  dim-22  dim-23     dim-24     dim-25     dim-26  \\\n",
       "0    0.000000  ...     0.0     0.0   5.597068  18.320045  14.764016   \n",
       "1    0.000000  ...     0.0     0.0   0.000000   6.180888  12.521391   \n",
       "2    1.523965  ...     0.0     0.0   0.263224   1.655028   5.390357   \n",
       "3    1.654186  ...     0.0     0.0   0.000000   0.000000   4.521163   \n",
       "4    0.805943  ...     0.0     0.0   6.028772   8.230105   5.101253   \n",
       "..        ...  ...     ...     ...        ...        ...        ...   \n",
       "995  0.000000  ...     0.0     0.0   0.005216   8.933444  15.012127   \n",
       "996  0.344437  ...     0.0     0.0   2.211108   0.350439   4.660242   \n",
       "997  0.000000  ...     0.0     0.0   1.039609   0.000000   2.340590   \n",
       "998  1.048411  ...     0.0     0.0   0.000000   1.956394   4.991206   \n",
       "999  9.116982  ...     0.0     0.0  15.125957   0.000000   0.000000   \n",
       "\n",
       "        dim-27     dim-28     dim-29     dim-30    dim-31  \n",
       "0     0.000000   7.787311  14.470059   6.384356  0.000000  \n",
       "1     3.648764   0.000000   4.218205   0.000000  0.000000  \n",
       "2     0.000000   0.000000   0.000000   0.000000  1.058898  \n",
       "3     3.160460   1.162947   0.000000   0.000000  0.000000  \n",
       "4     8.374162  21.305746  15.721295  19.534620  0.000000  \n",
       "..         ...        ...        ...        ...       ...  \n",
       "995   2.206023   0.000000   3.774734   0.000000  0.000000  \n",
       "996  11.047058  10.957180   3.310024   4.528979  0.000000  \n",
       "997   9.846880   0.000000   9.200933   0.000000  0.000000  \n",
       "998   0.331093   0.000000   1.939405   0.000000  0.000000  \n",
       "999   0.000000   0.000000   0.000000   8.377460  2.357505  \n",
       "\n",
       "[1000 rows x 34 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "373a284e-8b46-417e-acf4-430b511ddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../data/encoded-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
