{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b28ee-5261-4dd4-87b9-010886ce0861",
   "metadata": {},
   "source": [
    "# Data Encoder\n",
    "Uses an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bb738e-6c2c-4e35-8eba-5782d2076c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 10:04:49.832493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 10:04:50.351433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 10:04:51.125977: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:51.162574: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:51.162622: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"GPU is {'not ' if len(tf.config.list_physical_devices('GPU')) == 0 else ''}available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443139d0-df04-4673-afc3-a449c1526a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474614-0625-4708-941d-356be8639d67",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984d982-34ea-4b1c-b270-578980eabe18",
   "metadata": {},
   "source": [
    "The data should already be present as `dataset.csv` and `top_unigrams.txt` in the `data` folder.\n",
    "\n",
    "If they are not present, do the following.\n",
    "1. Ensure that the VirusTotal reports are present in `data/json` with the format `[LABEL]_[HASH].json`.\n",
    "3. Run `prepare_data.py`. This will generate the two files needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a156-3f24-489c-8f21-8227f806efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaf420-a415-4071-85f4-ea273992fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SALITY</td>\n",
       "      <td>e7fc7de574f44a966b198b7625bd6c595cad05bd669619...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADPOSHEL</td>\n",
       "      <td>fb576aea86528eaa082efbd073a7d4a6d1c2006da9ba49...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VEBZENPAK</td>\n",
       "      <td>4519186b8fb2eaa847255087b44f918928c20e97c2fbea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>MANSABO</td>\n",
       "      <td>78514a632682d1c07ee4f782302bb6a74f2676f1a91b56...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>958cceb0f7f7ae76b2527744da7e2305a372aff304d372...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>46401903e85a5c457490a6934ec4dc61fdf28df83af377...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>MINTLUKS</td>\n",
       "      <td>5f7d8b66dc6808f1f8181f342c3bb6ecce038a52622b48...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               hash  dim-0000  \\\n",
       "0      TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...         0   \n",
       "1     DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...         0   \n",
       "2        SALITY  e7fc7de574f44a966b198b7625bd6c595cad05bd669619...         0   \n",
       "3      ADPOSHEL  fb576aea86528eaa082efbd073a7d4a6d1c2006da9ba49...         0   \n",
       "4     VEBZENPAK  4519186b8fb2eaa847255087b44f918928c20e97c2fbea...         0   \n",
       "...         ...                                                ...       ...   \n",
       "4585    MANSABO  78514a632682d1c07ee4f782302bb6a74f2676f1a91b56...         0   \n",
       "4586     BENIGN  958cceb0f7f7ae76b2527744da7e2305a372aff304d372...         0   \n",
       "4587   TRICKBOT  46401903e85a5c457490a6934ec4dc61fdf28df83af377...         0   \n",
       "4588   TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...         0   \n",
       "4589   MINTLUKS  5f7d8b66dc6808f1f8181f342c3bb6ecce038a52622b48...         0   \n",
       "\n",
       "      dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  dim-0007  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         1         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4585         0         0         0         0         0         0         0   \n",
       "4586         0         0         0         0         0         0         0   \n",
       "4587         0         0         0         0         0         0         0   \n",
       "4588         0         0         0         0         0         0         0   \n",
       "4589         0         0         0         0         0         0         0   \n",
       "\n",
       "      ...  dim-9990  dim-9991  dim-9992  dim-9993  dim-9994  dim-9995  \\\n",
       "0     ...         0         0         0         0         0         0   \n",
       "1     ...         0         0         0         0         0         0   \n",
       "2     ...         0         0         0         0         0         0   \n",
       "3     ...         0         0         0         0         0         0   \n",
       "4     ...         0         1         0         0         0         0   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "4585  ...         0         0         0         0         0         0   \n",
       "4586  ...         0         0         0         0         0         0   \n",
       "4587  ...         0         0         0         0         0         0   \n",
       "4588  ...         0         0         0         0         0         0   \n",
       "4589  ...         0         0         0         0         0         0   \n",
       "\n",
       "      dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0  \n",
       "1            0         0         1         0  \n",
       "2            0         0         0         0  \n",
       "3            0         0         0         0  \n",
       "4            0         0         0         0  \n",
       "...        ...       ...       ...       ...  \n",
       "4585         0         0         1         0  \n",
       "4586         0         0         0         0  \n",
       "4587         0         0         1         0  \n",
       "4588         0         0         1         0  \n",
       "4589         0         0         0         0  \n",
       "\n",
       "[4590 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../data/dataset.csv\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58733-8a7d-492a-9177-3452980c5e16",
   "metadata": {},
   "source": [
    "For the training of the model, we don't need the label or the file hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4d0dbe-2bbf-4067-9376-b7dcf0ca0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>dim-0008</th>\n",
       "      <th>dim-0009</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         1         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4585         0         0         0         0         0         0         0   \n",
       "4586         0         0         0         0         0         0         0   \n",
       "4587         0         0         0         0         0         0         0   \n",
       "4588         0         0         0         0         0         0         0   \n",
       "4589         0         0         0         0         0         0         0   \n",
       "\n",
       "      dim-0007  dim-0008  dim-0009  ...  dim-9990  dim-9991  dim-9992  \\\n",
       "0            0         0         0  ...         0         0         0   \n",
       "1            0         0         0  ...         0         0         0   \n",
       "2            0         0         0  ...         0         0         0   \n",
       "3            0         0         0  ...         0         0         0   \n",
       "4            0         0         0  ...         0         1         0   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4585         0         0         0  ...         0         0         0   \n",
       "4586         0         0         0  ...         0         0         0   \n",
       "4587         0         0         0  ...         0         0         0   \n",
       "4588         0         0         0  ...         0         0         0   \n",
       "4589         0         0         0  ...         0         0         0   \n",
       "\n",
       "      dim-9993  dim-9994  dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0         0         0         0  \n",
       "1            0         0         0         0         0         1         0  \n",
       "2            0         0         0         0         0         0         0  \n",
       "3            0         0         0         0         0         0         0  \n",
       "4            0         0         0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4585         0         0         0         0         0         1         0  \n",
       "4586         0         0         0         0         0         0         0  \n",
       "4587         0         0         0         0         0         1         0  \n",
       "4588         0         0         0         0         0         1         0  \n",
       "4589         0         0         0         0         0         0         0  \n",
       "\n",
       "[4590 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=[\"label\", \"hash\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22399-a9af-45ec-a9b8-39db808eee27",
   "metadata": {},
   "source": [
    "80% of the dataframe will be saved for training, while 20% will be left for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057042e3-70e8-4e06-92d9-cc88f0b5cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3997e3ce-a8aa-40d2-aa00-e32ad3322da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3672, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5086b-0ac5-4e0f-b09f-470be173f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eea96-ff4f-4e5d-b5e2-ea82514726bb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215eea-b2ba-4577-984f-2e7e615f854c",
   "metadata": {},
   "source": [
    "We will use an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f209d9f2-8b37-4989-a939-2a28994be8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc4e4-676f-4d5a-bb9b-6a96fba0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_SIZES = [512, 256, 128, 32]  # The last layer is the center layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf29e26-b748-4fff-af16-8da3c9c459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EPOCH = 0\n",
    "\n",
    "def create_encoder():\n",
    "    model = Sequential(name=\"Encoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[:-1]:\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # Add an activity regularizer to make the middle layer sparse\n",
    "    model.add(layers.Dense(LAYER_SIZES[-1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_decoder():\n",
    "    model = Sequential(name=\"Decoder\")\n",
    "    model.add(keras.Input((LAYER_SIZES[-1],), name=\"decoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[-2::-1]:  # Starting from second last\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(layers.Dense(df.shape[1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_autoencoder(encoder, decoder):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "    model.add(encoder)\n",
    "    model.add(decoder)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a00874-3639-4045-9095-3f73f2e3ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 10:04:55.379451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:55.379536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:55.379568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:56.160487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:56.160614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:56.160623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-06 10:04:56.160660: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 10:04:56.160711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2715 MB memory:  -> device: 0, name: Quadro P1000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "autoencoder = create_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977b48f3-00f2-4281-a3b8-01fbafa39bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,298,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m5,288,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m5,120,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │     \u001b[38;5;34m5,298,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │     \u001b[38;5;34m5,130,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,587,696</span> (40.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,587,696\u001b[0m (40.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,587,696</span> (40.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,587,696\u001b[0m (40.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0668d-ef61-44b4-ac88-918bcc3cc14c",
   "metadata": {},
   "source": [
    "Define callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbefdc11-7c6d-440b-adea-5211bae96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"../models/encoder/checkpoint.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05e3cd-5fea-4b37-a1d0-53fa652ca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbf576-4890-433a-ab34-723878084111",
   "metadata": {},
   "source": [
    "Load latest checkpoint if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6c2489-b5df-46b6-922b-85b34d67ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_EPOCH = 54\n",
    "# autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eeb3c-f2c7-41a6-9472-1f876d13c927",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3223132-2248-4545-acc2-d41fbd131c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 10:04:56.853276: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 234960000 exceeds 10% of free system memory.\n",
      "2024-05-06 10:04:57.323282: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 234960000 exceeds 10% of free system memory.\n",
      "2024-05-06 10:04:57.432907: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 234960000 exceeds 10% of free system memory.\n",
      "2024-05-06 10:04:57.525790: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 234960000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714961098.927779 1104625 service.cc:145] XLA service 0x7f946400f8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714961098.927903 1104625 service.cc:153]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\n",
      "2024-05-06 10:04:58.963701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-06 10:04:59.848068: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/92\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0179 - mae: 0.0256"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714961102.372248 1104625 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0154 - mae: 0.0228\n",
      "Epoch 1: val_loss improved from inf to 0.01015, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - loss: 0.0154 - mae: 0.0227 - val_loss: 0.0102 - val_mae: 0.0146\n",
      "Epoch 2/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0097 - mae: 0.0138\n",
      "Epoch 2: val_loss improved from 0.01015 to 0.00909, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0097 - mae: 0.0138 - val_loss: 0.0091 - val_mae: 0.0130\n",
      "Epoch 3/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0087 - mae: 0.0122\n",
      "Epoch 3: val_loss improved from 0.00909 to 0.00839, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0122 - val_loss: 0.0084 - val_mae: 0.0114\n",
      "Epoch 4/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - mae: 0.0114\n",
      "Epoch 4: val_loss improved from 0.00839 to 0.00809, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - mae: 0.0114 - val_loss: 0.0081 - val_mae: 0.0112\n",
      "Epoch 5/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0107\n",
      "Epoch 5: val_loss improved from 0.00809 to 0.00778, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0078 - mae: 0.0107 - val_loss: 0.0078 - val_mae: 0.0107\n",
      "Epoch 6/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0076 - mae: 0.0105\n",
      "Epoch 6: val_loss improved from 0.00778 to 0.00756, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0076 - mae: 0.0105 - val_loss: 0.0076 - val_mae: 0.0102\n",
      "Epoch 7/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0072 - mae: 0.0099\n",
      "Epoch 7: val_loss improved from 0.00756 to 0.00748, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0072 - mae: 0.0099 - val_loss: 0.0075 - val_mae: 0.0102\n",
      "Epoch 8/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - mae: 0.0097\n",
      "Epoch 8: val_loss improved from 0.00748 to 0.00733, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0070 - mae: 0.0097 - val_loss: 0.0073 - val_mae: 0.0100\n",
      "Epoch 9/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - mae: 0.0094\n",
      "Epoch 9: val_loss improved from 0.00733 to 0.00718, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.0094 - val_loss: 0.0072 - val_mae: 0.0096\n",
      "Epoch 10/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065 - mae: 0.0089\n",
      "Epoch 10: val_loss improved from 0.00718 to 0.00713, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0089 - val_loss: 0.0071 - val_mae: 0.0097\n",
      "Epoch 11/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065 - mae: 0.0089\n",
      "Epoch 11: val_loss did not improve from 0.00713\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0065 - mae: 0.0089 - val_loss: 0.0074 - val_mae: 0.0103\n",
      "Epoch 12/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - mae: 0.0091\n",
      "Epoch 12: val_loss improved from 0.00713 to 0.00699, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0066 - mae: 0.0091 - val_loss: 0.0070 - val_mae: 0.0095\n",
      "Epoch 13/200\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0063 - mae: 0.0086\n",
      "Epoch 13: val_loss improved from 0.00699 to 0.00691, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0086 - val_loss: 0.0069 - val_mae: 0.0094\n",
      "Epoch 14/200\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0085\n",
      "Epoch 14: val_loss improved from 0.00691 to 0.00680, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0062 - mae: 0.0085 - val_loss: 0.0068 - val_mae: 0.0091\n",
      "Epoch 15/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - mae: 0.0083\n",
      "Epoch 15: val_loss improved from 0.00680 to 0.00674, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0083 - val_loss: 0.0067 - val_mae: 0.0092\n",
      "Epoch 16/200\n",
      "\u001b[1m88/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0082\n",
      "Epoch 16: val_loss improved from 0.00674 to 0.00670, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0061 - mae: 0.0082 - val_loss: 0.0067 - val_mae: 0.0090\n",
      "Epoch 17/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0079\n",
      "Epoch 17: val_loss improved from 0.00670 to 0.00665, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0079 - val_loss: 0.0066 - val_mae: 0.0088\n",
      "Epoch 18/200\n",
      "\u001b[1m88/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0079\n",
      "Epoch 18: val_loss improved from 0.00665 to 0.00663, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0079 - val_loss: 0.0066 - val_mae: 0.0089\n",
      "Epoch 19/200\n",
      "\u001b[1m88/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0077\n",
      "Epoch 19: val_loss improved from 0.00663 to 0.00658, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0077 - val_loss: 0.0066 - val_mae: 0.0088\n",
      "Epoch 20/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0076\n",
      "Epoch 20: val_loss improved from 0.00658 to 0.00652, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0065 - val_mae: 0.0087\n",
      "Epoch 21/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0075\n",
      "Epoch 21: val_loss did not improve from 0.00652\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0075 - val_loss: 0.0065 - val_mae: 0.0088\n",
      "Epoch 22/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0073\n",
      "Epoch 22: val_loss did not improve from 0.00652\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0054 - mae: 0.0073 - val_loss: 0.0065 - val_mae: 0.0086\n",
      "Epoch 23/200\n",
      "\u001b[1m89/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0077\n",
      "Epoch 23: val_loss did not improve from 0.00652\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0077 - val_loss: 0.0066 - val_mae: 0.0089\n",
      "Epoch 24/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0077\n",
      "Epoch 24: val_loss did not improve from 0.00652\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0077 - val_loss: 0.0065 - val_mae: 0.0088\n",
      "Epoch 25/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0074\n",
      "Epoch 25: val_loss improved from 0.00652 to 0.00645, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0055 - mae: 0.0074 - val_loss: 0.0065 - val_mae: 0.0087\n",
      "Epoch 26/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0073\n",
      "Epoch 26: val_loss improved from 0.00645 to 0.00641, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0054 - mae: 0.0073 - val_loss: 0.0064 - val_mae: 0.0085\n",
      "Epoch 27/200\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0077\n",
      "Epoch 27: val_loss improved from 0.00641 to 0.00634, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0063 - val_mae: 0.0084\n",
      "Epoch 28/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0070\n",
      "Epoch 28: val_loss did not improve from 0.00634\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0070 - val_loss: 0.0064 - val_mae: 0.0085\n",
      "Epoch 29/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0068\n",
      "Epoch 29: val_loss improved from 0.00634 to 0.00633, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0068 - val_loss: 0.0063 - val_mae: 0.0084\n",
      "Epoch 30/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - mae: 0.0069\n",
      "Epoch 30: val_loss improved from 0.00633 to 0.00629, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0053 - mae: 0.0069 - val_loss: 0.0063 - val_mae: 0.0083\n",
      "Epoch 31/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0068\n",
      "Epoch 31: val_loss did not improve from 0.00629\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0068 - val_loss: 0.0064 - val_mae: 0.0084\n",
      "Epoch 32/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0067\n",
      "Epoch 32: val_loss did not improve from 0.00629\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0067 - val_loss: 0.0063 - val_mae: 0.0084\n",
      "Epoch 33/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0069\n",
      "Epoch 33: val_loss improved from 0.00629 to 0.00624, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0052 - mae: 0.0069 - val_loss: 0.0062 - val_mae: 0.0082\n",
      "Epoch 34/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0068\n",
      "Epoch 34: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0068 - val_loss: 0.0062 - val_mae: 0.0082\n",
      "Epoch 35/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0066\n",
      "Epoch 35: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0066 - val_loss: 0.0062 - val_mae: 0.0082\n",
      "Epoch 36/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0068\n",
      "Epoch 36: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0068 - val_loss: 0.0063 - val_mae: 0.0083\n",
      "Epoch 37/200\n",
      "\u001b[1m89/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0068\n",
      "Epoch 37: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0068 - val_loss: 0.0063 - val_mae: 0.0083\n",
      "Epoch 38/200\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0068\n",
      "Epoch 38: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0068 - val_loss: 0.0063 - val_mae: 0.0081\n",
      "Epoch 39/200\n",
      "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0066\n",
      "Epoch 39: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0067 - val_loss: 0.0063 - val_mae: 0.0083\n",
      "Epoch 40/200\n",
      "\u001b[1m89/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0066\n",
      "Epoch 40: val_loss did not improve from 0.00624\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0049 - mae: 0.0066 - val_loss: 0.0063 - val_mae: 0.0084\n",
      "Epoch 40: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9553e105e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    validation_split=0.2,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624de2c-db5a-4f66-af5f-46a9ecda2cc6",
   "metadata": {},
   "source": [
    "Load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a49b423-df15-49b1-bf24-240085e1cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac822d-1e53-4f8f-8276-167436b59306",
   "metadata": {},
   "source": [
    "Evaluate the autoencoder on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4781808-0e8e-4ea4-881d-b8885317b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 10:05:57.885964: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 73440000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0062 - mae: 0.0080\n",
      "Testing MSE: 0.00619\n",
      "Testing MAE: 0.00804\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = autoencoder.evaluate(X_test, X_test, verbose=1)\n",
    "print(f\"Testing MSE: {test_mse:5.5f}\")\n",
    "print(f\"Testing MAE: {test_mae:5.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc591-1499-4c3e-9ba1-c987af35dee0",
   "metadata": {},
   "source": [
    "Get only the encoder part to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801a52f6-c52d-4c03-9cde-7821b653487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.get_layer(\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8480f9-8f94-4625-8a5e-4f6a55a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m5,120,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> (20.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,288,864\u001b[0m (20.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> (20.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,288,864\u001b[0m (20.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e40297ec-1e27-40ac-873e-e9c1725e5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"../models/encoder/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541ccc-227c-41b1-bc39-dfa5dcd3497f",
   "metadata": {},
   "source": [
    "# Transforming Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e958e27-424d-4d0b-b13e-9b4114b6cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_df = encoder.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe6b34d-e744-447b-9628-a6ef8b508b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(transformed_df, columns=[f\"dim-{i:02d}\" for i in range(LAYER_SIZES[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61444a4-2d51-4b52-808f-86733b39447c",
   "metadata": {},
   "source": [
    "Add the labels and hashes back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84f31a8a-5060-4541-bddf-afda870e351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.insert(0, \"label\", raw_df[\"label\"])\n",
    "transformed_df.insert(1, \"hash\", raw_df[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea1b33c5-5b44-4f0c-9996-a413474a9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-00</th>\n",
       "      <th>dim-01</th>\n",
       "      <th>dim-02</th>\n",
       "      <th>dim-03</th>\n",
       "      <th>dim-04</th>\n",
       "      <th>dim-05</th>\n",
       "      <th>dim-06</th>\n",
       "      <th>dim-07</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-22</th>\n",
       "      <th>dim-23</th>\n",
       "      <th>dim-24</th>\n",
       "      <th>dim-25</th>\n",
       "      <th>dim-26</th>\n",
       "      <th>dim-27</th>\n",
       "      <th>dim-28</th>\n",
       "      <th>dim-29</th>\n",
       "      <th>dim-30</th>\n",
       "      <th>dim-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>0.234683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112554</td>\n",
       "      <td>3.848537</td>\n",
       "      <td>10.626454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.636655</td>\n",
       "      <td>4.115376</td>\n",
       "      <td>...</td>\n",
       "      <td>11.081755</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.831595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.238762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.961174</td>\n",
       "      <td>4.955536</td>\n",
       "      <td>7.219052</td>\n",
       "      <td>6.404585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.986464</td>\n",
       "      <td>15.176069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.818527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.848658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.754366</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SALITY</td>\n",
       "      <td>e7fc7de574f44a966b198b7625bd6c595cad05bd669619...</td>\n",
       "      <td>1.887301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.101377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.977000</td>\n",
       "      <td>2.093550</td>\n",
       "      <td>...</td>\n",
       "      <td>6.317175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.234521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADPOSHEL</td>\n",
       "      <td>fb576aea86528eaa082efbd073a7d4a6d1c2006da9ba49...</td>\n",
       "      <td>9.481628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471548</td>\n",
       "      <td>13.774067</td>\n",
       "      <td>3.201977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.538937</td>\n",
       "      <td>2.335279</td>\n",
       "      <td>...</td>\n",
       "      <td>10.188432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.863317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.933706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.694593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VEBZENPAK</td>\n",
       "      <td>4519186b8fb2eaa847255087b44f918928c20e97c2fbea...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.298491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103305</td>\n",
       "      <td>8.573599</td>\n",
       "      <td>3.445668</td>\n",
       "      <td>8.807044</td>\n",
       "      <td>2.108075</td>\n",
       "      <td>...</td>\n",
       "      <td>6.378553</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.832773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220947</td>\n",
       "      <td>5.460258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>MANSABO</td>\n",
       "      <td>78514a632682d1c07ee4f782302bb6a74f2676f1a91b56...</td>\n",
       "      <td>4.159583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.365226</td>\n",
       "      <td>16.249929</td>\n",
       "      <td>8.144193</td>\n",
       "      <td>12.965709</td>\n",
       "      <td>4.145925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.732872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.190338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.085227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>958cceb0f7f7ae76b2527744da7e2305a372aff304d372...</td>\n",
       "      <td>0.505066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048248</td>\n",
       "      <td>0.290613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.703252</td>\n",
       "      <td>3.075265</td>\n",
       "      <td>5.338703</td>\n",
       "      <td>...</td>\n",
       "      <td>4.729104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.841697</td>\n",
       "      <td>5.468739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>46401903e85a5c457490a6934ec4dc61fdf28df83af377...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.437977</td>\n",
       "      <td>2.851583</td>\n",
       "      <td>15.546938</td>\n",
       "      <td>13.855932</td>\n",
       "      <td>18.300507</td>\n",
       "      <td>5.672984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.283621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.143718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.569523</td>\n",
       "      <td>6.198376</td>\n",
       "      <td>14.927482</td>\n",
       "      <td>9.734764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.672982</td>\n",
       "      <td>2.387461</td>\n",
       "      <td>12.033911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.245555</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>MINTLUKS</td>\n",
       "      <td>5f7d8b66dc6808f1f8181f342c3bb6ecce038a52622b48...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.774458</td>\n",
       "      <td>1.914858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.013348</td>\n",
       "      <td>7.266977</td>\n",
       "      <td>2.037490</td>\n",
       "      <td>3.132948</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.443942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253083</td>\n",
       "      <td>3.009083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.111658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               hash    dim-00  \\\n",
       "0      TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...  0.234683   \n",
       "1     DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...  0.000000   \n",
       "2        SALITY  e7fc7de574f44a966b198b7625bd6c595cad05bd669619...  1.887301   \n",
       "3      ADPOSHEL  fb576aea86528eaa082efbd073a7d4a6d1c2006da9ba49...  9.481628   \n",
       "4     VEBZENPAK  4519186b8fb2eaa847255087b44f918928c20e97c2fbea...  0.000000   \n",
       "...         ...                                                ...       ...   \n",
       "4585    MANSABO  78514a632682d1c07ee4f782302bb6a74f2676f1a91b56...  4.159583   \n",
       "4586     BENIGN  958cceb0f7f7ae76b2527744da7e2305a372aff304d372...  0.505066   \n",
       "4587   TRICKBOT  46401903e85a5c457490a6934ec4dc61fdf28df83af377...  0.000000   \n",
       "4588   TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...  0.000000   \n",
       "4589   MINTLUKS  5f7d8b66dc6808f1f8181f342c3bb6ecce038a52622b48...  0.000000   \n",
       "\n",
       "        dim-01    dim-02     dim-03     dim-04     dim-05    dim-06    dim-07  \\\n",
       "0     0.000000  1.112554   3.848537  10.626454   0.000000  8.636655  4.115376   \n",
       "1     0.000000  5.961174   4.955536   7.219052   6.404585  0.000000  0.000000   \n",
       "2     0.000000  3.101377   0.000000   0.000000   0.000000  8.977000  2.093550   \n",
       "3     0.000000  1.471548  13.774067   3.201977   0.000000  4.538937  2.335279   \n",
       "4     7.298491  0.000000   0.103305   8.573599   3.445668  8.807044  2.108075   \n",
       "...        ...       ...        ...        ...        ...       ...       ...   \n",
       "4585  0.000000  2.365226  16.249929   8.144193  12.965709  4.145925  0.000000   \n",
       "4586  0.000000  1.048248   0.290613   0.000000   2.703252  3.075265  5.338703   \n",
       "4587  2.437977  2.851583  15.546938  13.855932  18.300507  5.672984  0.000000   \n",
       "4588  0.000000  0.000000  10.569523   6.198376  14.927482  9.734764  0.000000   \n",
       "4589  9.774458  1.914858   0.000000   7.013348   7.266977  2.037490  3.132948   \n",
       "\n",
       "      ...     dim-22    dim-23     dim-24  dim-25    dim-26    dim-27  \\\n",
       "0     ...  11.081755  0.000044   0.000000     0.0  0.000000  0.000000   \n",
       "1     ...   0.000000  3.986464  15.176069     0.0  1.818527  0.000000   \n",
       "2     ...   6.317175  0.000000   0.000000     0.0  0.000000  0.000000   \n",
       "3     ...  10.188432  0.000000   5.863317     0.0  0.437514  0.000000   \n",
       "4     ...   6.378553  1.399800   1.832773     0.0  0.000000  0.000000   \n",
       "...   ...        ...       ...        ...     ...       ...       ...   \n",
       "4585  ...   0.000000  0.000000  18.732872     0.0  3.190338  0.000000   \n",
       "4586  ...   4.729104  0.000000   0.000000     0.0  0.000000  0.171386   \n",
       "4587  ...   0.000000  0.000000  16.283621     0.0  0.000000  0.000000   \n",
       "4588  ...   4.672982  2.387461  12.033911     0.0  0.270081  0.000000   \n",
       "4589  ...   3.385597  0.000000   6.443942     0.0  0.000000  0.253083   \n",
       "\n",
       "         dim-28    dim-29     dim-30  dim-31  \n",
       "0     15.831595  0.000000   7.238762     0.0  \n",
       "1     19.848658  0.000000   3.754366     0.0  \n",
       "2     13.234521  0.000000   0.323077     0.0  \n",
       "3      4.933706  0.000000  17.694593     0.0  \n",
       "4      0.000000  2.220947   5.460258     0.0  \n",
       "...         ...       ...        ...     ...  \n",
       "4585   8.085227  0.000000   0.000000     0.0  \n",
       "4586   0.000000  1.841697   5.468739     0.0  \n",
       "4587   6.143718  0.000000   0.000000     0.0  \n",
       "4588   0.000000  0.000000   7.245555     0.0  \n",
       "4589   3.009083  0.000000   7.111658     0.0  \n",
       "\n",
       "[4590 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "373a284e-8b46-417e-acf4-430b511ddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../data/encoded-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
