{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b28ee-5261-4dd4-87b9-010886ce0861",
   "metadata": {},
   "source": [
    "# Data Encoder\n",
    "Uses an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bb738e-6c2c-4e35-8eba-5782d2076c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 15:45:16.116636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 15:45:16.660845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 15:45:17.307602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:17.331361: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:17.331408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"GPU is {'not ' if len(tf.config.list_physical_devices('GPU')) == 0 else ''}available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443139d0-df04-4673-afc3-a449c1526a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474614-0625-4708-941d-356be8639d67",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984d982-34ea-4b1c-b270-578980eabe18",
   "metadata": {},
   "source": [
    "The data should already be present as `dataset.csv` and `top_unigrams.txt` in the `data` folder.\n",
    "\n",
    "If they are not present, do the following.\n",
    "1. Ensure that the VirusTotal reports are present in `data/json` with the format `[LABEL]_[HASH].json`.\n",
    "3. Run `prepare_data.py`. This will generate the two files needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a156-3f24-489c-8f21-8227f806efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaf420-a415-4071-85f4-ea273992fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COBALTSTRIKE</td>\n",
       "      <td>dab956e9c864a84d12e8106a24ac3cf2950394152c62b6...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>c40861e5ebd3c30de810f33c0959aaf5683586fe819998...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>9506421d996290f70689559ee0c09cc074c948fff49547...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               hash  \\\n",
       "0         TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...   \n",
       "1        DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...   \n",
       "2     INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "3     COBALTSTRIKE  dab956e9c864a84d12e8106a24ac3cf2950394152c62b6...   \n",
       "4          UNKNOWN  c40861e5ebd3c30de810f33c0959aaf5683586fe819998...   \n",
       "...            ...                                                ...   \n",
       "1568      TRICKBOT  9506421d996290f70689559ee0c09cc074c948fff49547...   \n",
       "1569       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "1570      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "1571       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "1572      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "      dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1568         0         0         0         0         0         0         0   \n",
       "1569         0         0         0         0         0         0         0   \n",
       "1570         0         0         0         0         0         0         0   \n",
       "1571         0         0         0         0         0         0         0   \n",
       "1572         0         0         0         0         0         0         0   \n",
       "\n",
       "      dim-0007  ...  dim-9990  dim-9991  dim-9992  dim-9993  dim-9994  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         1         0   \n",
       "2            0  ...         0         0         0         0         0   \n",
       "3            0  ...         0         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "1568         0  ...         0         0         0         0         0   \n",
       "1569         0  ...         0         0         0         0         0   \n",
       "1570         0  ...         0         1         0         0         0   \n",
       "1571         0  ...         0         0         0         0         0   \n",
       "1572         0  ...         0         0         0         0         0   \n",
       "\n",
       "      dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         1         1  \n",
       "2            0         0         0         0         0  \n",
       "3            0         0         0         0         0  \n",
       "4            0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1568         0         0         0         1         0  \n",
       "1569         0         0         0         0         0  \n",
       "1570         0         0         0         0         0  \n",
       "1571         0         0         0         0         0  \n",
       "1572         0         0         0         1         0  \n",
       "\n",
       "[1573 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../data/dataset.csv\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58733-8a7d-492a-9177-3452980c5e16",
   "metadata": {},
   "source": [
    "For the training of the model, we don't need the label or the file hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4d0dbe-2bbf-4067-9376-b7dcf0ca0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>dim-0008</th>\n",
       "      <th>dim-0009</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1568         0         0         0         0         0         0         0   \n",
       "1569         0         0         0         0         0         0         0   \n",
       "1570         0         0         0         0         0         0         0   \n",
       "1571         0         0         0         0         0         0         0   \n",
       "1572         0         0         0         0         0         0         0   \n",
       "\n",
       "      dim-0007  dim-0008  dim-0009  ...  dim-9990  dim-9991  dim-9992  \\\n",
       "0            0         0         0  ...         0         0         0   \n",
       "1            0         0         0  ...         0         0         0   \n",
       "2            0         0         0  ...         0         0         0   \n",
       "3            0         0         0  ...         0         0         0   \n",
       "4            0         0         0  ...         0         0         0   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1568         0         0         0  ...         0         0         0   \n",
       "1569         0         0         0  ...         0         0         0   \n",
       "1570         0         0         0  ...         0         1         0   \n",
       "1571         0         0         0  ...         0         0         0   \n",
       "1572         0         0         0  ...         0         0         0   \n",
       "\n",
       "      dim-9993  dim-9994  dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0         0         0         0  \n",
       "1            1         0         0         0         0         1         1  \n",
       "2            0         0         0         0         0         0         0  \n",
       "3            0         0         0         0         0         0         0  \n",
       "4            0         0         0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1568         0         0         0         0         0         1         0  \n",
       "1569         0         0         0         0         0         0         0  \n",
       "1570         0         0         0         0         0         0         0  \n",
       "1571         0         0         0         0         0         0         0  \n",
       "1572         0         0         0         0         0         1         0  \n",
       "\n",
       "[1573 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=[\"label\", \"hash\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22399-a9af-45ec-a9b8-39db808eee27",
   "metadata": {},
   "source": [
    "80% of the dataframe will be saved for training, while 20% will be left for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057042e3-70e8-4e06-92d9-cc88f0b5cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3997e3ce-a8aa-40d2-aa00-e32ad3322da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5086b-0ac5-4e0f-b09f-470be173f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eea96-ff4f-4e5d-b5e2-ea82514726bb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215eea-b2ba-4577-984f-2e7e615f854c",
   "metadata": {},
   "source": [
    "We will use an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f209d9f2-8b37-4989-a939-2a28994be8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc4e4-676f-4d5a-bb9b-6a96fba0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_SIZES = [512, 256, 128, 32]  # The last layer is the center layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf29e26-b748-4fff-af16-8da3c9c459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EPOCH = 0\n",
    "\n",
    "def create_encoder():\n",
    "    model = Sequential(name=\"Encoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[:-1]:\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # Add an activity regularizer to make the middle layer sparse\n",
    "    model.add(layers.Dense(LAYER_SIZES[-1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_decoder():\n",
    "    model = Sequential(name=\"Decoder\")\n",
    "    model.add(keras.Input((LAYER_SIZES[-1],), name=\"decoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[-2::-1]:  # Starting from second last\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(layers.Dense(df.shape[1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_autoencoder(encoder, decoder):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "    model.add(encoder)\n",
    "    model.add(decoder)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a00874-3639-4045-9095-3f73f2e3ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 15:45:18.998114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:18.998206: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:18.998238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:19.713066: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:19.713254: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:19.713266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 15:45:19.713342: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 15:45:19.713375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2715 MB memory:  -> device: 0, name: Quadro P1000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "autoencoder = create_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977b48f3-00f2-4281-a3b8-01fbafa39bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,298,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m5,288,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m5,120,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │     \u001b[38;5;34m5,298,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │     \u001b[38;5;34m5,130,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,587,696</span> (40.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,587,696\u001b[0m (40.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,587,696</span> (40.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,587,696\u001b[0m (40.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0668d-ef61-44b4-ac88-918bcc3cc14c",
   "metadata": {},
   "source": [
    "Define callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbefdc11-7c6d-440b-adea-5211bae96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"../models/encoder/checkpoint.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05e3cd-5fea-4b37-a1d0-53fa652ca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbf576-4890-433a-ab34-723878084111",
   "metadata": {},
   "source": [
    "Load latest checkpoint if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6c2489-b5df-46b6-922b-85b34d67ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_EPOCH = 54\n",
    "# autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eeb3c-f2c7-41a6-9472-1f876d13c927",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3223132-2248-4545-acc2-d41fbd131c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714376721.648620 1190698 service.cc:145] XLA service 0x7f0624005fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714376721.648681 1190698 service.cc:153]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\n",
      "2024-04-29 15:45:21.680168: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 15:45:22.582892: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0186 - mae: 0.0264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714376725.084993 1190698 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0178 - mae: 0.0259\n",
      "Epoch 1: val_loss improved from inf to 0.01451, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - loss: 0.0177 - mae: 0.0258 - val_loss: 0.0145 - val_mae: 0.0209\n",
      "Epoch 2/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0198\n",
      "Epoch 2: val_loss improved from 0.01451 to 0.01269, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0135 - mae: 0.0197 - val_loss: 0.0127 - val_mae: 0.0185\n",
      "Epoch 3/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0168\n",
      "Epoch 3: val_loss improved from 0.01269 to 0.01152, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0115 - mae: 0.0167 - val_loss: 0.0115 - val_mae: 0.0163\n",
      "Epoch 4/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0152\n",
      "Epoch 4: val_loss improved from 0.01152 to 0.01081, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0107 - mae: 0.0152 - val_loss: 0.0108 - val_mae: 0.0151\n",
      "Epoch 5/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0144\n",
      "Epoch 5: val_loss improved from 0.01081 to 0.01042, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0103 - mae: 0.0144 - val_loss: 0.0104 - val_mae: 0.0144\n",
      "Epoch 6/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093 - mae: 0.0129\n",
      "Epoch 6: val_loss improved from 0.01042 to 0.01004, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0093 - mae: 0.0129 - val_loss: 0.0100 - val_mae: 0.0139\n",
      "Epoch 7/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - mae: 0.0126\n",
      "Epoch 7: val_loss improved from 0.01004 to 0.00997, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0091 - mae: 0.0126 - val_loss: 0.0100 - val_mae: 0.0137\n",
      "Epoch 8/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0089 - mae: 0.0124\n",
      "Epoch 8: val_loss improved from 0.00997 to 0.00963, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0089 - mae: 0.0124 - val_loss: 0.0096 - val_mae: 0.0132\n",
      "Epoch 9/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0087 - mae: 0.0120\n",
      "Epoch 9: val_loss improved from 0.00963 to 0.00945, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0087 - mae: 0.0120 - val_loss: 0.0095 - val_mae: 0.0130\n",
      "Epoch 10/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - mae: 0.0116\n",
      "Epoch 10: val_loss improved from 0.00945 to 0.00919, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0083 - mae: 0.0116 - val_loss: 0.0092 - val_mae: 0.0128\n",
      "Epoch 11/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0115\n",
      "Epoch 11: val_loss improved from 0.00919 to 0.00903, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0082 - mae: 0.0115 - val_loss: 0.0090 - val_mae: 0.0122\n",
      "Epoch 12/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0108\n",
      "Epoch 12: val_loss improved from 0.00903 to 0.00889, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0078 - mae: 0.0108 - val_loss: 0.0089 - val_mae: 0.0121\n",
      "Epoch 13/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0112\n",
      "Epoch 13: val_loss improved from 0.00889 to 0.00871, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0082 - mae: 0.0111 - val_loss: 0.0087 - val_mae: 0.0118\n",
      "Epoch 14/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0076 - mae: 0.0103\n",
      "Epoch 14: val_loss did not improve from 0.00871\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - mae: 0.0103 - val_loss: 0.0088 - val_mae: 0.0119\n",
      "Epoch 15/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0107\n",
      "Epoch 15: val_loss improved from 0.00871 to 0.00856, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0078 - mae: 0.0106 - val_loss: 0.0086 - val_mae: 0.0117\n",
      "Epoch 16/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - mae: 0.0103\n",
      "Epoch 16: val_loss improved from 0.00856 to 0.00855, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0075 - mae: 0.0102 - val_loss: 0.0085 - val_mae: 0.0116\n",
      "Epoch 17/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0072 - mae: 0.0099\n",
      "Epoch 17: val_loss improved from 0.00855 to 0.00848, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0072 - mae: 0.0099 - val_loss: 0.0085 - val_mae: 0.0114\n",
      "Epoch 18/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - mae: 0.0096\n",
      "Epoch 18: val_loss improved from 0.00848 to 0.00830, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0096 - val_loss: 0.0083 - val_mae: 0.0110\n",
      "Epoch 19/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0092\n",
      "Epoch 19: val_loss did not improve from 0.00830\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0083 - val_mae: 0.0112\n",
      "Epoch 20/200\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - mae: 0.0093\n",
      "Epoch 20: val_loss improved from 0.00830 to 0.00824, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0069 - mae: 0.0093 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 21/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - mae: 0.0092\n",
      "Epoch 21: val_loss improved from 0.00824 to 0.00818, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0068 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0107\n",
      "Epoch 22/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0069 - mae: 0.0093\n",
      "Epoch 22: val_loss did not improve from 0.00818\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - mae: 0.0093 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 23/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0092\n",
      "Epoch 23: val_loss did not improve from 0.00818\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 24/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0093\n",
      "Epoch 24: val_loss did not improve from 0.00818\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mae: 0.0093 - val_loss: 0.0083 - val_mae: 0.0113\n",
      "Epoch 25/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - mae: 0.0093\n",
      "Epoch 25: val_loss improved from 0.00818 to 0.00812, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0068 - mae: 0.0093 - val_loss: 0.0081 - val_mae: 0.0108\n",
      "Epoch 26/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0091\n",
      "Epoch 26: val_loss did not improve from 0.00812\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mae: 0.0091 - val_loss: 0.0082 - val_mae: 0.0109\n",
      "Epoch 27/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065 - mae: 0.0089\n",
      "Epoch 27: val_loss did not improve from 0.00812\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - mae: 0.0089 - val_loss: 0.0082 - val_mae: 0.0111\n",
      "Epoch 28/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - mae: 0.0088\n",
      "Epoch 28: val_loss improved from 0.00812 to 0.00804, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0064 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0107\n",
      "Epoch 29/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - mae: 0.0088\n",
      "Epoch 29: val_loss improved from 0.00804 to 0.00795, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0064 - mae: 0.0088 - val_loss: 0.0079 - val_mae: 0.0105\n",
      "Epoch 30/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0084\n",
      "Epoch 30: val_loss improved from 0.00795 to 0.00792, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0062 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0105\n",
      "Epoch 31/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - mae: 0.0083\n",
      "Epoch 31: val_loss improved from 0.00792 to 0.00787, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0061 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 32/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0076\n",
      "Epoch 32: val_loss did not improve from 0.00787\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0076 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 33/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0076\n",
      "Epoch 33: val_loss did not improve from 0.00787\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 34/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0078\n",
      "Epoch 34: val_loss did not improve from 0.00787\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 35/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0077\n",
      "Epoch 35: val_loss improved from 0.00787 to 0.00783, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0058 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0102\n",
      "Epoch 36/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0076\n",
      "Epoch 36: val_loss did not improve from 0.00783\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0076 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 37/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0075\n",
      "Epoch 37: val_loss did not improve from 0.00783\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0075 - val_loss: 0.0078 - val_mae: 0.0102\n",
      "Epoch 38/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0074\n",
      "Epoch 38: val_loss improved from 0.00783 to 0.00779, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0056 - mae: 0.0074 - val_loss: 0.0078 - val_mae: 0.0100\n",
      "Epoch 39/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0074\n",
      "Epoch 39: val_loss did not improve from 0.00779\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0074 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 40/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0071\n",
      "Epoch 40: val_loss did not improve from 0.00779\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - mae: 0.0071 - val_loss: 0.0078 - val_mae: 0.0102\n",
      "Epoch 41/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0073\n",
      "Epoch 41: val_loss did not improve from 0.00779\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0073 - val_loss: 0.0079 - val_mae: 0.0103\n",
      "Epoch 42/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0077\n",
      "Epoch 42: val_loss did not improve from 0.00779\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0101\n",
      "Epoch 43/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0074\n",
      "Epoch 43: val_loss improved from 0.00779 to 0.00772, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0057 - mae: 0.0074 - val_loss: 0.0077 - val_mae: 0.0099\n",
      "Epoch 44/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0073\n",
      "Epoch 44: val_loss did not improve from 0.00772\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0073 - val_loss: 0.0077 - val_mae: 0.0099\n",
      "Epoch 45/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - mae: 0.0068\n",
      "Epoch 45: val_loss did not improve from 0.00772\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - mae: 0.0068 - val_loss: 0.0077 - val_mae: 0.0098\n",
      "Epoch 46/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - mae: 0.0067\n",
      "Epoch 46: val_loss improved from 0.00772 to 0.00770, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0053 - mae: 0.0067 - val_loss: 0.0077 - val_mae: 0.0097\n",
      "Epoch 47/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0065\n",
      "Epoch 47: val_loss did not improve from 0.00770\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0077 - val_mae: 0.0097\n",
      "Epoch 48/200\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0065\n",
      "Epoch 48: val_loss did not improve from 0.00770\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0077 - val_mae: 0.0098\n",
      "Epoch 48: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f06e6c562b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    validation_split=0.2,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624de2c-db5a-4f66-af5f-46a9ecda2cc6",
   "metadata": {},
   "source": [
    "Load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a49b423-df15-49b1-bf24-240085e1cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac822d-1e53-4f8f-8276-167436b59306",
   "metadata": {},
   "source": [
    "Evaluate the autoencoder on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4781808-0e8e-4ea4-881d-b8885317b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0070 - mae: 0.0089\n",
      "Testing MSE: 0.00699\n",
      "Testing MAE: 0.00882\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = autoencoder.evaluate(X_test, X_test, verbose=1)\n",
    "print(f\"Testing MSE: {test_mse:5.5f}\")\n",
    "print(f\"Testing MAE: {test_mae:5.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc591-1499-4c3e-9ba1-c987af35dee0",
   "metadata": {},
   "source": [
    "Get only the encoder part to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801a52f6-c52d-4c03-9cde-7821b653487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.get_layer(\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8480f9-8f94-4625-8a5e-4f6a55a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m5,120,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> (20.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,288,864\u001b[0m (20.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,288,864</span> (20.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,288,864\u001b[0m (20.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e40297ec-1e27-40ac-873e-e9c1725e5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"../models/encoder/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541ccc-227c-41b1-bc39-dfa5dcd3497f",
   "metadata": {},
   "source": [
    "# Transforming Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e958e27-424d-4d0b-b13e-9b4114b6cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_df = encoder.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe6b34d-e744-447b-9628-a6ef8b508b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(transformed_df, columns=[f\"dim-{i:02d}\" for i in range(LAYER_SIZES[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61444a4-2d51-4b52-808f-86733b39447c",
   "metadata": {},
   "source": [
    "Add the labels and hashes back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84f31a8a-5060-4541-bddf-afda870e351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.insert(0, \"label\", raw_df[\"label\"])\n",
    "transformed_df.insert(1, \"hash\", raw_df[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea1b33c5-5b44-4f0c-9996-a413474a9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-00</th>\n",
       "      <th>dim-01</th>\n",
       "      <th>dim-02</th>\n",
       "      <th>dim-03</th>\n",
       "      <th>dim-04</th>\n",
       "      <th>dim-05</th>\n",
       "      <th>dim-06</th>\n",
       "      <th>dim-07</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-22</th>\n",
       "      <th>dim-23</th>\n",
       "      <th>dim-24</th>\n",
       "      <th>dim-25</th>\n",
       "      <th>dim-26</th>\n",
       "      <th>dim-27</th>\n",
       "      <th>dim-28</th>\n",
       "      <th>dim-29</th>\n",
       "      <th>dim-30</th>\n",
       "      <th>dim-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>7.549576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.502934</td>\n",
       "      <td>24.176189</td>\n",
       "      <td>15.322744</td>\n",
       "      <td>6.537903</td>\n",
       "      <td>17.014332</td>\n",
       "      <td>...</td>\n",
       "      <td>3.867043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.907426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.940077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.619308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.847561</td>\n",
       "      <td>7.412828</td>\n",
       "      <td>...</td>\n",
       "      <td>12.765860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.257461</td>\n",
       "      <td>12.005179</td>\n",
       "      <td>13.770399</td>\n",
       "      <td>12.168733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>13.003604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.939367</td>\n",
       "      <td>21.694796</td>\n",
       "      <td>11.356659</td>\n",
       "      <td>6.433365</td>\n",
       "      <td>16.684380</td>\n",
       "      <td>...</td>\n",
       "      <td>18.388371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.366971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.011396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COBALTSTRIKE</td>\n",
       "      <td>dab956e9c864a84d12e8106a24ac3cf2950394152c62b6...</td>\n",
       "      <td>9.411519</td>\n",
       "      <td>11.802638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.384830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.831763</td>\n",
       "      <td>9.012511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.769751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.577077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.902426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>c40861e5ebd3c30de810f33c0959aaf5683586fe819998...</td>\n",
       "      <td>4.599778</td>\n",
       "      <td>4.875384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.622899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.233712</td>\n",
       "      <td>3.769575</td>\n",
       "      <td>5.864996</td>\n",
       "      <td>...</td>\n",
       "      <td>3.280627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.568317</td>\n",
       "      <td>0.744919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.647032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.844474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>9506421d996290f70689559ee0c09cc074c948fff49547...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.429248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.549780</td>\n",
       "      <td>15.505765</td>\n",
       "      <td>13.514245</td>\n",
       "      <td>...</td>\n",
       "      <td>20.763781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.163751</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>20.171080</td>\n",
       "      <td>4.978172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.767549</td>\n",
       "      <td>13.185392</td>\n",
       "      <td>17.561668</td>\n",
       "      <td>4.622786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.819319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.469461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>7.412106</td>\n",
       "      <td>3.795544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.510063</td>\n",
       "      <td>9.629321</td>\n",
       "      <td>6.728159</td>\n",
       "      <td>...</td>\n",
       "      <td>16.329901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.062054</td>\n",
       "      <td>8.711801</td>\n",
       "      <td>12.110841</td>\n",
       "      <td>13.719257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.587579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>5.062665</td>\n",
       "      <td>3.779000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.753929</td>\n",
       "      <td>0.457823</td>\n",
       "      <td>7.567391</td>\n",
       "      <td>...</td>\n",
       "      <td>6.432997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.620044</td>\n",
       "      <td>1.316070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.945687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.418612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.187121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.682913</td>\n",
       "      <td>20.807047</td>\n",
       "      <td>7.209068</td>\n",
       "      <td>...</td>\n",
       "      <td>14.775033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.779606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.309707</td>\n",
       "      <td>9.176167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               hash  \\\n",
       "0         TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...   \n",
       "1        DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...   \n",
       "2     INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "3     COBALTSTRIKE  dab956e9c864a84d12e8106a24ac3cf2950394152c62b6...   \n",
       "4          UNKNOWN  c40861e5ebd3c30de810f33c0959aaf5683586fe819998...   \n",
       "...            ...                                                ...   \n",
       "1568      TRICKBOT  9506421d996290f70689559ee0c09cc074c948fff49547...   \n",
       "1569       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "1570      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "1571       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "1572      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "         dim-00     dim-01  dim-02     dim-03     dim-04     dim-05  \\\n",
       "0      7.549576   0.000000     0.0   8.502934  24.176189  15.322744   \n",
       "1      0.000000   0.000000     0.0  14.619308   0.000000   0.000000   \n",
       "2     13.003604   0.000000     0.0  16.939367  21.694796  11.356659   \n",
       "3      9.411519  11.802638     0.0   8.384830   0.000000   7.831763   \n",
       "4      4.599778   4.875384     0.0   2.622899   0.000000  12.233712   \n",
       "...         ...        ...     ...        ...        ...        ...   \n",
       "1568   0.000000   0.000000     0.0  12.429248   0.000000  13.549780   \n",
       "1569  20.171080   4.978172     0.0   0.000000   3.767549  13.185392   \n",
       "1570   7.412106   3.795544     0.0   3.142282   0.000000   8.510063   \n",
       "1571   5.062665   3.779000     0.0   0.000000   0.000000  11.753929   \n",
       "1572   0.000000   0.000000     0.0  14.187121   0.000000  19.682913   \n",
       "\n",
       "         dim-06     dim-07  ...     dim-22  dim-23    dim-24    dim-25  \\\n",
       "0      6.537903  17.014332  ...   3.867043     0.0  2.907426  0.000000   \n",
       "1     16.847561   7.412828  ...  12.765860     0.0  0.000000  9.257461   \n",
       "2      6.433365  16.684380  ...  18.388371     0.0  3.366971  0.000000   \n",
       "3      9.012511   0.000000  ...   0.000000     0.0  0.000000  7.769751   \n",
       "4      3.769575   5.864996  ...   3.280627     0.0  1.568317  0.744919   \n",
       "...         ...        ...  ...        ...     ...       ...       ...   \n",
       "1568  15.505765  13.514245  ...  20.763781     0.0  0.000000  0.000000   \n",
       "1569  17.561668   4.622786  ...   0.373729     0.0  0.000000  6.819319   \n",
       "1570   9.629321   6.728159  ...  16.329901     0.0  6.062054  8.711801   \n",
       "1571   0.457823   7.567391  ...   6.432997     0.0  2.620044  1.316070   \n",
       "1572  20.807047   7.209068  ...  14.775033     0.0  2.779606  0.000000   \n",
       "\n",
       "         dim-26     dim-27     dim-28  dim-29  dim-30     dim-31  \n",
       "0      0.000000  14.940077   0.000000     0.0     0.0   0.000000  \n",
       "1     12.005179  13.770399  12.168733     0.0     0.0   8.010514  \n",
       "2      0.000000  22.011396   0.000000     0.0     0.0   0.000000  \n",
       "3      0.000000   4.577077   0.000000     0.0     0.0   8.902426  \n",
       "4      0.000000   4.647032   0.000000     0.0     0.0   6.844474  \n",
       "...         ...        ...        ...     ...     ...        ...  \n",
       "1568   6.163751   0.922269   0.000000     0.0     0.0   1.915500  \n",
       "1569   0.000000   5.469461   0.000000     0.0     0.0   0.000000  \n",
       "1570  12.110841  13.719257   0.000000     0.0     0.0  10.587579  \n",
       "1571   0.000000   3.945687   0.000000     0.0     0.0   4.418612  \n",
       "1572   2.309707   9.176167   0.000000     0.0     0.0   2.110210  \n",
       "\n",
       "[1573 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "373a284e-8b46-417e-acf4-430b511ddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../data/encoded-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
