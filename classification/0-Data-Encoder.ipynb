{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b28ee-5261-4dd4-87b9-010886ce0861",
   "metadata": {},
   "source": [
    "# Data Encoder\n",
    "Uses an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bb738e-6c2c-4e35-8eba-5782d2076c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:12:39.433465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 13:12:40.018157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:12:40.838192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:40.873254: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:40.873306: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"GPU is {'not ' if len(tf.config.list_physical_devices('GPU')) == 0 else ''}available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443139d0-df04-4673-afc3-a449c1526a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474614-0625-4708-941d-356be8639d67",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984d982-34ea-4b1c-b270-578980eabe18",
   "metadata": {},
   "source": [
    "The data should already be present as `dataset.csv` and `top_unigrams.txt` in the `data` folder.\n",
    "\n",
    "If they are not present, do the following.\n",
    "1. Ensure that the VirusTotal reports are present in `data/json` with the format `[LABEL]_[HASH].json`.\n",
    "3. Run `prepare_data.py`. This will generate the two files needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a156-3f24-489c-8f21-8227f806efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaf420-a415-4071-85f4-ea273992fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>c40861e5ebd3c30de810f33c0959aaf5683586fe819998...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WALDEK</td>\n",
       "      <td>26714e389dbb964ddd764ee4f1bceaf56b18adc8734668...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>9506421d996290f70689559ee0c09cc074c948fff49547...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1273 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               hash  \\\n",
       "0         TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...   \n",
       "1        DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...   \n",
       "2     INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "3          UNKNOWN  c40861e5ebd3c30de810f33c0959aaf5683586fe819998...   \n",
       "4           WALDEK  26714e389dbb964ddd764ee4f1bceaf56b18adc8734668...   \n",
       "...            ...                                                ...   \n",
       "1268      TRICKBOT  9506421d996290f70689559ee0c09cc074c948fff49547...   \n",
       "1269       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "1270      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "1271       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "1272      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "      dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1268         0         0         0         0         0         0         0   \n",
       "1269         0         0         0         0         0         0         0   \n",
       "1270         0         0         0         0         0         0         0   \n",
       "1271         0         0         0         0         0         0         0   \n",
       "1272         0         0         0         0         0         0         0   \n",
       "\n",
       "      dim-0007  ...  dim-9990  dim-9991  dim-9992  dim-9993  dim-9994  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         1         0         0         0   \n",
       "2            0  ...         0         0         0         0         0   \n",
       "3            0  ...         0         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "1268         0  ...         0         0         0         0         0   \n",
       "1269         0  ...         0         0         0         0         0   \n",
       "1270         0  ...         0         0         0         0         0   \n",
       "1271         0  ...         0         0         0         0         0   \n",
       "1272         0  ...         0         0         0         0         0   \n",
       "\n",
       "      dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         0         0  \n",
       "2            0         0         0         0         0  \n",
       "3            0         0         0         0         0  \n",
       "4            0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1268         0         0         0         0         0  \n",
       "1269         0         0         0         0         0  \n",
       "1270         0         0         0         0         0  \n",
       "1271         0         0         0         0         0  \n",
       "1272         0         0         0         0         0  \n",
       "\n",
       "[1273 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"../data/dataset.csv\")\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58733-8a7d-492a-9177-3452980c5e16",
   "metadata": {},
   "source": [
    "For the training of the model, we don't need the label or the file hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4d0dbe-2bbf-4067-9376-b7dcf0ca0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim-0000</th>\n",
       "      <th>dim-0001</th>\n",
       "      <th>dim-0002</th>\n",
       "      <th>dim-0003</th>\n",
       "      <th>dim-0004</th>\n",
       "      <th>dim-0005</th>\n",
       "      <th>dim-0006</th>\n",
       "      <th>dim-0007</th>\n",
       "      <th>dim-0008</th>\n",
       "      <th>dim-0009</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-9990</th>\n",
       "      <th>dim-9991</th>\n",
       "      <th>dim-9992</th>\n",
       "      <th>dim-9993</th>\n",
       "      <th>dim-9994</th>\n",
       "      <th>dim-9995</th>\n",
       "      <th>dim-9996</th>\n",
       "      <th>dim-9997</th>\n",
       "      <th>dim-9998</th>\n",
       "      <th>dim-9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1273 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dim-0000  dim-0001  dim-0002  dim-0003  dim-0004  dim-0005  dim-0006  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1268         0         0         0         0         0         0         0   \n",
       "1269         0         0         0         0         0         0         0   \n",
       "1270         0         0         0         0         0         0         0   \n",
       "1271         0         0         0         0         0         0         0   \n",
       "1272         0         0         0         0         0         0         0   \n",
       "\n",
       "      dim-0007  dim-0008  dim-0009  ...  dim-9990  dim-9991  dim-9992  \\\n",
       "0            0         0         0  ...         0         0         0   \n",
       "1            0         0         0  ...         0         1         0   \n",
       "2            0         0         0  ...         0         0         0   \n",
       "3            0         0         0  ...         0         0         0   \n",
       "4            0         0         0  ...         0         0         0   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1268         0         0         0  ...         0         0         0   \n",
       "1269         0         0         0  ...         0         0         0   \n",
       "1270         0         1         0  ...         0         0         0   \n",
       "1271         0         0         0  ...         0         0         0   \n",
       "1272         0         0         0  ...         0         0         0   \n",
       "\n",
       "      dim-9993  dim-9994  dim-9995  dim-9996  dim-9997  dim-9998  dim-9999  \n",
       "0            0         0         0         0         0         0         0  \n",
       "1            0         0         0         0         0         0         0  \n",
       "2            0         0         0         0         0         0         0  \n",
       "3            0         0         0         0         0         0         0  \n",
       "4            0         0         0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1268         0         0         0         0         0         0         0  \n",
       "1269         0         0         0         0         0         0         0  \n",
       "1270         0         0         0         0         0         0         0  \n",
       "1271         0         0         0         0         0         0         0  \n",
       "1272         0         0         0         0         0         0         0  \n",
       "\n",
       "[1273 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=[\"label\", \"hash\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22399-a9af-45ec-a9b8-39db808eee27",
   "metadata": {},
   "source": [
    "80% of the dataframe will be saved for training, while 20% will be left for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057042e3-70e8-4e06-92d9-cc88f0b5cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3997e3ce-a8aa-40d2-aa00-e32ad3322da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df5086b-0ac5-4e0f-b09f-470be173f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eea96-ff4f-4e5d-b5e2-ea82514726bb",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215eea-b2ba-4577-984f-2e7e615f854c",
   "metadata": {},
   "source": [
    "We will use an autoencoder to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f209d9f2-8b37-4989-a939-2a28994be8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920dc4e4-676f-4d5a-bb9b-6a96fba0311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_SIZES = [2048, 512, 128, 32]  # The last layer is the center layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf29e26-b748-4fff-af16-8da3c9c459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EPOCH = 0\n",
    "\n",
    "def create_encoder():\n",
    "    model = Sequential(name=\"Encoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[:-1]:\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # Add an activity regularizer to make the middle layer sparse\n",
    "    model.add(layers.Dense(LAYER_SIZES[-1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_decoder():\n",
    "    model = Sequential(name=\"Decoder\")\n",
    "    model.add(keras.Input((LAYER_SIZES[-1],), name=\"decoder-input\"))\n",
    "\n",
    "    for layer_size in LAYER_SIZES[-2::-1]:  # Starting from second last\n",
    "        model.add(layers.Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(layers.Dense(df.shape[1], activation=\"relu\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_autoencoder(encoder, decoder):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    model.add(keras.Input((df.shape[1],), name=\"encoder-input\"))\n",
    "    model.add(encoder)\n",
    "    model.add(decoder)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a00874-3639-4045-9095-3f73f2e3ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:12:42.297475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:42.297570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:42.297617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:43.045692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:43.045778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:43.045787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 13:12:43.045825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 13:12:43.045849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2715 MB memory:  -> device: 0, name: Quadro P1000, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "decoder = create_decoder()\n",
    "autoencoder = create_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977b48f3-00f2-4281-a3b8-01fbafa39bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,610,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │    \u001b[38;5;34m21,600,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_2 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_3 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m21,610,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_4 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_5 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)          │    \u001b[38;5;34m20,490,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,211,824</span> (164.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,211,824\u001b[0m (164.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0668d-ef61-44b4-ac88-918bcc3cc14c",
   "metadata": {},
   "source": [
    "Define callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbefdc11-7c6d-440b-adea-5211bae96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"../models/encoder/checkpoint.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05e3cd-5fea-4b37-a1d0-53fa652ca4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbf576-4890-433a-ab34-723878084111",
   "metadata": {},
   "source": [
    "Load latest checkpoint if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6c2489-b5df-46b6-922b-85b34d67ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_EPOCH = 54\n",
    "# autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eeb3c-f2c7-41a6-9472-1f876d13c927",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3223132-2248-4545-acc2-d41fbd131c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714367565.043334  916026 service.cc:145] XLA service 0x7f1fc000e180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714367565.043418  916026 service.cc:153]   StreamExecutor device (0): Quadro P1000, Compute Capability 6.1\n",
      "2024-04-29 13:12:45.075737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 13:12:45.891269: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/26\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0192 - mae: 0.0246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714367568.650307  916026 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0173 - mae: 0.0254\n",
      "Epoch 1: val_loss improved from inf to 0.01299, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - loss: 0.0173 - mae: 0.0253 - val_loss: 0.0130 - val_mae: 0.0189\n",
      "Epoch 2/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0139 - mae: 0.0207\n",
      "Epoch 2: val_loss improved from 0.01299 to 0.01114, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0138 - mae: 0.0206 - val_loss: 0.0111 - val_mae: 0.0169\n",
      "Epoch 3/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0118 - mae: 0.0174\n",
      "Epoch 3: val_loss improved from 0.01114 to 0.01038, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0118 - mae: 0.0174 - val_loss: 0.0104 - val_mae: 0.0152\n",
      "Epoch 4/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0108 - mae: 0.0158\n",
      "Epoch 4: val_loss improved from 0.01038 to 0.00965, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0108 - mae: 0.0158 - val_loss: 0.0097 - val_mae: 0.0141\n",
      "Epoch 5/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0098 - mae: 0.0140\n",
      "Epoch 5: val_loss improved from 0.00965 to 0.00921, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0098 - mae: 0.0140 - val_loss: 0.0092 - val_mae: 0.0132\n",
      "Epoch 6/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0095 - mae: 0.0135\n",
      "Epoch 6: val_loss improved from 0.00921 to 0.00912, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0095 - mae: 0.0135 - val_loss: 0.0091 - val_mae: 0.0131\n",
      "Epoch 7/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0091 - mae: 0.0130\n",
      "Epoch 7: val_loss improved from 0.00912 to 0.00889, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0091 - mae: 0.0130 - val_loss: 0.0089 - val_mae: 0.0125\n",
      "Epoch 8/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0088 - mae: 0.0123\n",
      "Epoch 8: val_loss improved from 0.00889 to 0.00856, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0088 - mae: 0.0123 - val_loss: 0.0086 - val_mae: 0.0120\n",
      "Epoch 9/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0087 - mae: 0.0122\n",
      "Epoch 9: val_loss did not improve from 0.00856\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0087 - mae: 0.0122 - val_loss: 0.0086 - val_mae: 0.0121\n",
      "Epoch 10/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0085 - mae: 0.0119\n",
      "Epoch 10: val_loss improved from 0.00856 to 0.00840, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0085 - mae: 0.0119 - val_loss: 0.0084 - val_mae: 0.0117\n",
      "Epoch 11/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0084 - mae: 0.0117\n",
      "Epoch 11: val_loss improved from 0.00840 to 0.00825, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0084 - mae: 0.0117 - val_loss: 0.0083 - val_mae: 0.0116\n",
      "Epoch 12/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0079 - mae: 0.0109\n",
      "Epoch 12: val_loss improved from 0.00825 to 0.00807, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0079 - mae: 0.0109 - val_loss: 0.0081 - val_mae: 0.0111\n",
      "Epoch 13/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0113\n",
      "Epoch 13: val_loss did not improve from 0.00807\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0080 - mae: 0.0112 - val_loss: 0.0081 - val_mae: 0.0112\n",
      "Epoch 14/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0077 - mae: 0.0107\n",
      "Epoch 14: val_loss improved from 0.00807 to 0.00802, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0078 - mae: 0.0107 - val_loss: 0.0080 - val_mae: 0.0110\n",
      "Epoch 15/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0103\n",
      "Epoch 15: val_loss did not improve from 0.00802\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0075 - mae: 0.0103 - val_loss: 0.0081 - val_mae: 0.0112\n",
      "Epoch 16/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - mae: 0.0105\n",
      "Epoch 16: val_loss improved from 0.00802 to 0.00790, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0075 - mae: 0.0105 - val_loss: 0.0079 - val_mae: 0.0109\n",
      "Epoch 17/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0101\n",
      "Epoch 17: val_loss did not improve from 0.00790\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0073 - mae: 0.0101 - val_loss: 0.0083 - val_mae: 0.0115\n",
      "Epoch 18/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0076 - mae: 0.0107\n",
      "Epoch 18: val_loss improved from 0.00790 to 0.00777, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0076 - mae: 0.0107 - val_loss: 0.0078 - val_mae: 0.0106\n",
      "Epoch 19/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0099\n",
      "Epoch 19: val_loss did not improve from 0.00777\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0072 - mae: 0.0099 - val_loss: 0.0081 - val_mae: 0.0112\n",
      "Epoch 20/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0077 - mae: 0.0107\n",
      "Epoch 20: val_loss did not improve from 0.00777\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0077 - mae: 0.0107 - val_loss: 0.0079 - val_mae: 0.0111\n",
      "Epoch 21/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - mae: 0.0106\n",
      "Epoch 21: val_loss improved from 0.00777 to 0.00773, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0075 - mae: 0.0106 - val_loss: 0.0077 - val_mae: 0.0107\n",
      "Epoch 22/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - mae: 0.0103\n",
      "Epoch 22: val_loss did not improve from 0.00773\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0073 - mae: 0.0103 - val_loss: 0.0079 - val_mae: 0.0108\n",
      "Epoch 23/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - mae: 0.0102\n",
      "Epoch 23: val_loss improved from 0.00773 to 0.00768, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0074 - mae: 0.0102 - val_loss: 0.0077 - val_mae: 0.0105\n",
      "Epoch 24/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0071 - mae: 0.0098\n",
      "Epoch 24: val_loss improved from 0.00768 to 0.00758, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0071 - mae: 0.0097 - val_loss: 0.0076 - val_mae: 0.0103\n",
      "Epoch 25/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0070 - mae: 0.0096\n",
      "Epoch 25: val_loss improved from 0.00758 to 0.00747, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0070 - mae: 0.0096 - val_loss: 0.0075 - val_mae: 0.0101\n",
      "Epoch 26/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0067 - mae: 0.0092\n",
      "Epoch 26: val_loss did not improve from 0.00747\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0100\n",
      "Epoch 27/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0068 - mae: 0.0093\n",
      "Epoch 27: val_loss did not improve from 0.00747\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0068 - mae: 0.0093 - val_loss: 0.0075 - val_mae: 0.0102\n",
      "Epoch 28/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0088\n",
      "Epoch 28: val_loss did not improve from 0.00747\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0088 - val_loss: 0.0075 - val_mae: 0.0102\n",
      "Epoch 29/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0086\n",
      "Epoch 29: val_loss improved from 0.00747 to 0.00734, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0064 - mae: 0.0086 - val_loss: 0.0073 - val_mae: 0.0097\n",
      "Epoch 30/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mae: 0.0084\n",
      "Epoch 30: val_loss did not improve from 0.00734\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0062 - mae: 0.0084 - val_loss: 0.0075 - val_mae: 0.0099\n",
      "Epoch 31/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0085\n",
      "Epoch 31: val_loss did not improve from 0.00734\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0063 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0102\n",
      "Epoch 32/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0068 - mae: 0.0093\n",
      "Epoch 32: val_loss did not improve from 0.00734\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0102\n",
      "Epoch 33/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0084\n",
      "Epoch 33: val_loss did not improve from 0.00734\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0102\n",
      "Epoch 34/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0086\n",
      "Epoch 34: val_loss did not improve from 0.00734\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0063 - mae: 0.0086 - val_loss: 0.0075 - val_mae: 0.0100\n",
      "Epoch 35/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0088\n",
      "Epoch 35: val_loss improved from 0.00734 to 0.00732, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0064 - mae: 0.0088 - val_loss: 0.0073 - val_mae: 0.0098\n",
      "Epoch 36/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - mae: 0.0088\n",
      "Epoch 36: val_loss did not improve from 0.00732\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0087 - val_loss: 0.0074 - val_mae: 0.0099\n",
      "Epoch 37/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0083\n",
      "Epoch 37: val_loss did not improve from 0.00732\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0060 - mae: 0.0083 - val_loss: 0.0074 - val_mae: 0.0098\n",
      "Epoch 38/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0083\n",
      "Epoch 38: val_loss improved from 0.00732 to 0.00730, saving model to ../models/encoder/checkpoint.keras\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0061 - mae: 0.0083 - val_loss: 0.0073 - val_mae: 0.0097\n",
      "Epoch 39/200\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0061 - mae: 0.0082\n",
      "Epoch 39: val_loss did not improve from 0.00730\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0061 - mae: 0.0082 - val_loss: 0.0074 - val_mae: 0.0098\n",
      "Epoch 39: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2100781730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    validation_split=0.2,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624de2c-db5a-4f66-af5f-46a9ecda2cc6",
   "metadata": {},
   "source": [
    "Load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a49b423-df15-49b1-bf24-240085e1cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac822d-1e53-4f8f-8276-167436b59306",
   "metadata": {},
   "source": [
    "Evaluate the autoencoder on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4781808-0e8e-4ea4-881d-b8885317b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0074 - mae: 0.0099\n",
      "Testing MSE: 0.00733\n",
      "Testing MAE: 0.00988\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = autoencoder.evaluate(X_test, X_test, verbose=1)\n",
    "print(f\"Testing MSE: {test_mse:5.5f}\")\n",
    "print(f\"Testing MAE: {test_mae:5.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc591-1499-4c3e-9ba1-c987af35dee0",
   "metadata": {},
   "source": [
    "Get only the encoder part to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801a52f6-c52d-4c03-9cde-7821b653487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.get_layer(\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8480f9-8f94-4625-8a5e-4f6a55a34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,482,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,482,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,600,928</span> (82.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,600,928\u001b[0m (82.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e40297ec-1e27-40ac-873e-e9c1725e5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"../models/encoder/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541ccc-227c-41b1-bc39-dfa5dcd3497f",
   "metadata": {},
   "source": [
    "# Transforming Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e958e27-424d-4d0b-b13e-9b4114b6cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "transformed_df = encoder.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe6b34d-e744-447b-9628-a6ef8b508b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(transformed_df, columns=[f\"dim-{i:02d}\" for i in range(LAYER_SIZES[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61444a4-2d51-4b52-808f-86733b39447c",
   "metadata": {},
   "source": [
    "Add the labels and hashes back to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84f31a8a-5060-4541-bddf-afda870e351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.insert(0, \"label\", raw_df[\"label\"])\n",
    "transformed_df.insert(1, \"hash\", raw_df[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea1b33c5-5b44-4f0c-9996-a413474a9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>hash</th>\n",
       "      <th>dim-00</th>\n",
       "      <th>dim-01</th>\n",
       "      <th>dim-02</th>\n",
       "      <th>dim-03</th>\n",
       "      <th>dim-04</th>\n",
       "      <th>dim-05</th>\n",
       "      <th>dim-06</th>\n",
       "      <th>dim-07</th>\n",
       "      <th>...</th>\n",
       "      <th>dim-22</th>\n",
       "      <th>dim-23</th>\n",
       "      <th>dim-24</th>\n",
       "      <th>dim-25</th>\n",
       "      <th>dim-26</th>\n",
       "      <th>dim-27</th>\n",
       "      <th>dim-28</th>\n",
       "      <th>dim-29</th>\n",
       "      <th>dim-30</th>\n",
       "      <th>dim-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>f16631469eb35406ef4049d30c763cadda571b25bbdb45...</td>\n",
       "      <td>10.802482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.707260</td>\n",
       "      <td>9.048082</td>\n",
       "      <td>8.721670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.428146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801215</td>\n",
       "      <td>10.506460</td>\n",
       "      <td>0.024712</td>\n",
       "      <td>0.138089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DARKKOMET</td>\n",
       "      <td>d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...</td>\n",
       "      <td>16.677288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.798045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.046454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.214973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.833573</td>\n",
       "      <td>6.818852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTALLBRAIN</td>\n",
       "      <td>a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...</td>\n",
       "      <td>19.391300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.920878</td>\n",
       "      <td>12.444473</td>\n",
       "      <td>13.511684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.542971</td>\n",
       "      <td>7.226212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.421442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>c40861e5ebd3c30de810f33c0959aaf5683586fe819998...</td>\n",
       "      <td>1.521830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.158831</td>\n",
       "      <td>0.561619</td>\n",
       "      <td>5.079782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.686564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.877486</td>\n",
       "      <td>2.747570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.483807</td>\n",
       "      <td>2.246307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WALDEK</td>\n",
       "      <td>26714e389dbb964ddd764ee4f1bceaf56b18adc8734668...</td>\n",
       "      <td>2.786578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.454260</td>\n",
       "      <td>2.999919</td>\n",
       "      <td>11.366814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.534671</td>\n",
       "      <td>1.490412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.255082</td>\n",
       "      <td>2.657059</td>\n",
       "      <td>2.279361</td>\n",
       "      <td>2.798004</td>\n",
       "      <td>3.320712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>9506421d996290f70689559ee0c09cc074c948fff49547...</td>\n",
       "      <td>15.698259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.621684</td>\n",
       "      <td>5.317119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.855600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.220627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>NECONYD</td>\n",
       "      <td>0eee965f286f057a3175797590795bbf99fda65dc8d845...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.607330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.734159</td>\n",
       "      <td>13.946035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.253247</td>\n",
       "      <td>4.843779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.935575</td>\n",
       "      <td>7.204690</td>\n",
       "      <td>11.374994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...</td>\n",
       "      <td>6.559162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.169443</td>\n",
       "      <td>9.100674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.957123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.151663</td>\n",
       "      <td>6.178844</td>\n",
       "      <td>7.022230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.627770</td>\n",
       "      <td>0.871398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.418483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.741640</td>\n",
       "      <td>3.873108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.095950</td>\n",
       "      <td>0.103331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>TRICKBOT</td>\n",
       "      <td>7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...</td>\n",
       "      <td>9.510083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.756887</td>\n",
       "      <td>6.264085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.609660</td>\n",
       "      <td>3.584152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.162540</td>\n",
       "      <td>12.635226</td>\n",
       "      <td>12.565152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1273 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               hash  \\\n",
       "0         TRICKBOT  f16631469eb35406ef4049d30c763cadda571b25bbdb45...   \n",
       "1        DARKKOMET  d31a7102cbc54447c251ba62760eb484fd0c9fbb8ea54f...   \n",
       "2     INSTALLBRAIN  a5ba68828e571de66675befdf4fbaf26dd226e25c2c703...   \n",
       "3          UNKNOWN  c40861e5ebd3c30de810f33c0959aaf5683586fe819998...   \n",
       "4           WALDEK  26714e389dbb964ddd764ee4f1bceaf56b18adc8734668...   \n",
       "...            ...                                                ...   \n",
       "1268      TRICKBOT  9506421d996290f70689559ee0c09cc074c948fff49547...   \n",
       "1269       NECONYD  0eee965f286f057a3175797590795bbf99fda65dc8d845...   \n",
       "1270      TRICKBOT  0c6aa0ae05d5fa8bf5a8ea95310be73ee60e55a0ce6864...   \n",
       "1271       UNKNOWN  08b4e7389242e3b8c37215a3b972f69193a9a12d5130bf...   \n",
       "1272      TRICKBOT  7eca38a5d0098a7ca4baa1faca43b80b5f911b7580273b...   \n",
       "\n",
       "         dim-00  dim-01  dim-02    dim-03     dim-04     dim-05     dim-06  \\\n",
       "0     10.802482     0.0     0.0  0.000000   0.000000  12.707260   9.048082   \n",
       "1     16.677288     0.0     0.0  0.000000  13.798045   0.000000   3.046454   \n",
       "2     19.391300     0.0     0.0  0.000000   0.000000   7.920878  12.444473   \n",
       "3      1.521830     0.0     0.0  1.158831   0.561619   5.079782   0.000000   \n",
       "4      2.786578     0.0     0.0  0.740827   0.000000   3.454260   2.999919   \n",
       "...         ...     ...     ...       ...        ...        ...        ...   \n",
       "1268  15.698259     0.0     0.0  0.000000  13.621684   5.317119   0.000000   \n",
       "1269   0.000000     0.0     0.0  1.607330   0.000000   0.000000   4.734159   \n",
       "1270   6.559162     0.0     0.0  0.000000   0.000000   0.000000   8.169443   \n",
       "1271   0.000000     0.0     0.0  0.000000   1.627770   0.871398   0.000000   \n",
       "1272   9.510083     0.0     0.0  0.000000  19.756887   6.264085   0.000000   \n",
       "\n",
       "         dim-07  ...  dim-22     dim-23    dim-24  dim-25    dim-26    dim-27  \\\n",
       "0      8.721670  ...     0.0  13.428146  0.000000     0.0  0.000000  0.000000   \n",
       "1      0.000000  ...     0.0  11.214973  0.000000     0.0  0.000000  8.833573   \n",
       "2     13.511684  ...     0.0   6.118662  0.000000     0.0  0.000000  0.000000   \n",
       "3      4.686564  ...     0.0   4.877486  2.747570     0.0  0.000000  0.000000   \n",
       "4     11.366814  ...     0.0   8.534671  1.490412     0.0  0.000000  4.255082   \n",
       "...         ...  ...     ...        ...       ...     ...       ...       ...   \n",
       "1268   0.000000  ...     0.0  11.855600  0.000000     0.0  0.000000  0.000000   \n",
       "1269  13.946035  ...     0.0   2.253247  4.843779     0.0  0.000000  3.935575   \n",
       "1270   9.100674  ...     0.0  10.957123  0.000000     0.0  4.151663  6.178844   \n",
       "1271   7.418483  ...     0.0   4.741640  3.873108     0.0  0.000000  0.000000   \n",
       "1272   0.000000  ...     0.0   8.609660  3.584152     0.0  0.000000  1.162540   \n",
       "\n",
       "         dim-28     dim-29    dim-30    dim-31  \n",
       "0      0.801215  10.506460  0.024712  0.138089  \n",
       "1      6.818852   0.000000  0.000000  0.000000  \n",
       "2      4.542971   7.226212  0.000000  1.421442  \n",
       "3      0.000000   2.483807  2.246307  0.000000  \n",
       "4      2.657059   2.279361  2.798004  3.320712  \n",
       "...         ...        ...       ...       ...  \n",
       "1268   0.000000   3.220627  0.000000  0.000000  \n",
       "1269   7.204690  11.374994  0.000000  0.000000  \n",
       "1270   7.022230   0.000000  0.000000  0.000000  \n",
       "1271   0.000000   0.000000  4.095950  0.103331  \n",
       "1272  12.635226  12.565152  0.000000  0.000000  \n",
       "\n",
       "[1273 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "373a284e-8b46-417e-acf4-430b511ddc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../data/encoded-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
